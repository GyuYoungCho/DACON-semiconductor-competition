{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "import numpy as np\n",
    "warnings.filterwarnings('ignore')\n",
    "train = pd.read_csv('trains.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "for col in train.columns:\n",
    "    col_type = train[col].dtypes\n",
    "    min1 = train[col].min()\n",
    "    max1 = train[col].max()\n",
    "    if str(col_type)[:3] == 'int':\n",
    "        train[col] = train[col].astype(np.int16)\n",
    "    else:\n",
    "        if min1 > np.finfo(np.float16).min and max1 < np.finfo(np.float16).max:\n",
    "            train[col] = train[col].astype(np.float16)\n",
    "        elif min1 > np.finfo(np.float32).min and max1 < np.finfo(np.float32).max:\n",
    "            train[col] = train[col].astype(np.float32)\n",
    "        else:\n",
    "            train[col] = train[col].astype(np.float64)\n",
    "train_X = train.iloc[:,4:]\n",
    "train_Y = train.iloc[:,0:4]\n",
    "test_X = test.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "i = np.random.choice(np.arange(0,810000), 10000, replace=False)\n",
    "train_set = train_X.drop(i,axis=0) ,train_Y.drop(i,axis=0)\n",
    "val_set = train_X.loc[i] ,train_Y.loc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras import optimizers\n",
    "from keras import activations\n",
    "def build_model(lr, dropout_rate=0.5):\n",
    "    uni = 160\n",
    "    model = Sequential()\n",
    "    model.add(Dense(uni, activation=swish, input_dim=226))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(uni, activation=swish, input_dim=226))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(uni, activation=swish, input_dim=226))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(uni, activation=swish, input_dim=226))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(uni, activation=swish, input_dim=226))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(uni, activation=swish, input_dim=226))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(uni, activation=swish, input_dim=226))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(uni, activation=swish, input_dim=226))\n",
    "    model.add(Dense(uni, activation=swish, input_dim=226))\n",
    "    model.add(Dense(4, activation='linear'))\n",
    "    op = optimizers.Nadam(learning_rate=lr, beta_1 = 0.9, beta_2 = 0.999)\n",
    "    model.compile(loss='mae', optimizer=op, metrics=['mae'])\n",
    "    return model\n",
    "def swish(x) :\n",
    "    return x * keras.activations.sigmoid(x)\n",
    "\n",
    "def mish(x) :\n",
    "    return x * keras.activations.tanh(keras.activations.softplus(x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_with(verbose, lr, dropout_rate):\n",
    "    model = build_model(lr, dropout_rate)\n",
    "    fit_with = model.fit(train_set[0],train_set[1], epochs=15, batch_size=1000, shuffle=True)\n",
    "    e_val = model.evaluate(val_set[0],val_set[1],steps=10, verbose=0)\n",
    "    print('Test loss:', e_val[0])\n",
    "    print('Test score:', e_val[1])\n",
    "    return e_val[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "verbose = 1\n",
    "fit_with_partial = partial(fit_with, verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | dropou... |    lr     |\n",
      "-------------------------------------------------\n",
      "Epoch 1/15\n",
      "800000/800000 [==============================] - 18s 23us/step - loss: 53.6197 - mae: 53.6197\n",
      "Epoch 2/15\n",
      "800000/800000 [==============================] - 16s 20us/step - loss: 27.2449 - mae: 27.2449\n",
      "Epoch 3/15\n",
      "800000/800000 [==============================] - 16s 20us/step - loss: 18.1218 - mae: 18.1218\n",
      "Epoch 4/15\n",
      "800000/800000 [==============================] - 16s 20us/step - loss: 15.0752 - mae: 15.0751\n",
      "Epoch 5/15\n",
      "800000/800000 [==============================] - 16s 20us/step - loss: 13.4544 - mae: 13.4544\n",
      "Epoch 6/15\n",
      "800000/800000 [==============================] - 16s 20us/step - loss: 12.5549 - mae: 12.5549\n",
      "Epoch 7/15\n",
      "800000/800000 [==============================] - 16s 21us/step - loss: 11.7580 - mae: 11.7580\n",
      "Epoch 8/15\n",
      "800000/800000 [==============================] - 17s 21us/step - loss: 11.2582 - mae: 11.2582\n",
      "Epoch 9/15\n",
      "800000/800000 [==============================] - 17s 21us/step - loss: 10.8033 - mae: 10.8033 1\n",
      "Epoch 10/15\n",
      "800000/800000 [==============================] - 16s 21us/step - loss: 10.4634 - mae: 10.4634\n",
      "Epoch 11/15\n",
      "800000/800000 [==============================] - 16s 21us/step - loss: 10.1140 - mae: 10.1140\n",
      "Epoch 12/15\n",
      "800000/800000 [==============================] - 16s 21us/step - loss: 9.9041 - mae: 9.9041\n",
      "Epoch 13/15\n",
      "800000/800000 [==============================] - 16s 21us/step - loss: 9.6080 - mae: 9.6080 3s - loss: 9.6290 - mae:  - ETA: 0s - loss: 9.6113 -\n",
      "Epoch 14/15\n",
      "800000/800000 [==============================] - 17s 21us/step - loss: 9.3719 - mae: 9.3719 3s - loss: 9 - \n",
      "Epoch 15/15\n",
      "800000/800000 [==============================] - 16s 20us/step - loss: 9.1821 - mae: 9.1821\n",
      "Test loss: 0.7748504638671875\n",
      "Test score: 77.48505115509033\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.7749  \u001b[0m | \u001b[0m 0.2085  \u001b[0m | \u001b[0m 0.007231\u001b[0m |\n",
      "Epoch 1/15\n",
      "800000/800000 [==============================] - 18s 22us/step - loss: 46.5248 - mae: 46.5248\n",
      "Epoch 2/15\n",
      "800000/800000 [==============================] - 16s 20us/step - loss: 15.3703 - mae: 15.3703\n",
      "Epoch 3/15\n",
      "800000/800000 [==============================] - 17s 21us/step - loss: 9.8746 - mae: 9.8746\n",
      "Epoch 4/15\n",
      "800000/800000 [==============================] - 16s 21us/step - loss: 8.0244 - mae: 8.0244\n",
      "Epoch 5/15\n",
      "800000/800000 [==============================] - 17s 21us/step - loss: 6.9795 - mae: 6.9795 1s - loss: 7.0099 - mae: 7. - ETA: 1s - loss\n",
      "Epoch 6/15\n",
      "800000/800000 [==============================] - 17s 21us/step - loss: 6.3106 - mae: 6.3106\n",
      "Epoch 7/15\n",
      "800000/800000 [==============================] - 16s 21us/step - loss: 5.8924 - mae: 5.8924\n",
      "Epoch 8/15\n",
      "800000/800000 [==============================] - 17s 21us/step - loss: 5.5406 - mae: 5.5406 0s - loss: 5.5458 - mae: \n",
      "Epoch 9/15\n",
      "800000/800000 [==============================] - 17s 21us/step - loss: 5.2450 - mae: 5.2450\n",
      "Epoch 10/15\n",
      "800000/800000 [==============================] - 17s 21us/step - loss: 4.9901 - mae: 4.9901\n",
      "Epoch 11/15\n",
      "800000/800000 [==============================] - 17s 21us/step - loss: 4.7769 - mae: 4.7769 0s - loss: 4.7765 - ma\n",
      "Epoch 12/15\n",
      "800000/800000 [==============================] - 17s 21us/step - loss: 4.6243 - mae: 4.6243\n",
      "Epoch 13/15\n",
      "800000/800000 [==============================] - 16s 21us/step - loss: 4.4916 - mae: 4.4916\n",
      "Epoch 14/15\n",
      "800000/800000 [==============================] - 17s 21us/step - loss: 4.3770 - mae: 4.3770\n",
      "Epoch 15/15\n",
      "800000/800000 [==============================] - 17s 21us/step - loss: 4.2708 - mae: 4.2708\n",
      "Test loss: 0.4608459949493408\n",
      "Test score: 46.084598541259766\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.4608  \u001b[0m | \u001b[0m 5.719e-0\u001b[0m | \u001b[0m 0.003093\u001b[0m |\n",
      "Epoch 1/15\n",
      "800000/800000 [==============================] - 18s 22us/step - loss: 56.0713 - mae: 56.0713\n",
      "Epoch 2/15\n",
      "800000/800000 [==============================] - 16s 20us/step - loss: 25.3311 - mae: 25.3311\n",
      "Epoch 3/15\n",
      "800000/800000 [==============================] - 16s 20us/step - loss: 15.3269 - mae: 15.3269\n",
      "Epoch 4/15\n",
      "800000/800000 [==============================] - 16s 20us/step - loss: 11.9900 - mae: 11.9900\n",
      "Epoch 5/15\n",
      "800000/800000 [==============================] - 16s 20us/step - loss: 10.2369 - mae: 10.2369\n",
      "Epoch 6/15\n",
      "800000/800000 [==============================] - 16s 20us/step - loss: 9.1427 - mae: 9.1427\n",
      "Epoch 7/15\n",
      "800000/800000 [==============================] - 16s 20us/step - loss: 8.3975 - mae: 8.3975\n",
      "Epoch 8/15\n",
      "800000/800000 [==============================] - 16s 20us/step - loss: 7.8277 - mae: 7.8277 0s - loss: 7.8280 - mae: 7.828\n",
      "Epoch 9/15\n",
      "800000/800000 [==============================] - 16s 20us/step - loss: 7.3899 - mae: 7.3899\n",
      "Epoch 10/15\n",
      "800000/800000 [==============================] - 16s 20us/step - loss: 7.0499 - mae: 7.0499\n",
      "Epoch 11/15\n",
      "800000/800000 [==============================] - 16s 20us/step - loss: 6.7736 - mae: 6.7736\n",
      "Epoch 12/15\n",
      "800000/800000 [==============================] - 16s 20us/step - loss: 6.4899 - mae: 6.4899\n",
      "Epoch 13/15\n",
      "800000/800000 [==============================] - 16s 20us/step - loss: 6.3248 - mae: 6.3248 2s - loss: 6.3337 - mae:\n",
      "Epoch 14/15\n",
      "800000/800000 [==============================] - 16s 20us/step - loss: 6.1398 - mae: 6.1398\n",
      "Epoch 15/15\n",
      "800000/800000 [==============================] - 16s 20us/step - loss: 5.9682 - mae: 5.9682\n",
      "Test loss: 0.40981688499450686\n",
      "Test score: 40.981688499450684\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.4098  \u001b[0m | \u001b[0m 0.07338 \u001b[0m | \u001b[0m 0.001014\u001b[0m |\n",
      "Epoch 1/15\n",
      "800000/800000 [==============================] - 18s 22us/step - loss: 49.6190 - mae: 49.6190\n",
      "Epoch 2/15\n",
      "800000/800000 [==============================] - 16s 20us/step - loss: 18.5977 - mae: 18.5977\n",
      "Epoch 3/15\n",
      "800000/800000 [==============================] - 17s 21us/step - loss: 12.5161 - mae: 12.5161\n",
      "Epoch 4/15\n",
      "800000/800000 [==============================] - 16s 20us/step - loss: 10.4347 - mae: 10.4347\n",
      "Epoch 5/15\n",
      "800000/800000 [==============================] - 16s 20us/step - loss: 9.3039 - mae: 9.3039 \n",
      "Epoch 6/15\n",
      "800000/800000 [==============================] - 17s 21us/step - loss: 8.5787 - mae: 8.5787\n",
      "Epoch 7/15\n",
      "800000/800000 [==============================] - 16s 20us/step - loss: 8.1038 - mae: 8.1038\n",
      "Epoch 8/15\n",
      "800000/800000 [==============================] - 16s 20us/step - loss: 7.6964 - mae: 7.6964\n",
      "Epoch 9/15\n",
      "800000/800000 [==============================] - 16s 20us/step - loss: 7.3610 - mae: 7.3610\n",
      "Epoch 10/15\n",
      "800000/800000 [==============================] - 16s 20us/step - loss: 7.1047 - mae: 7.1047\n",
      "Epoch 11/15\n",
      "800000/800000 [==============================] - 16s 20us/step - loss: 6.9114 - mae: 6.9114\n",
      "Epoch 12/15\n",
      "800000/800000 [==============================] - 17s 22us/step - loss: 6.6732 - mae: 6.6732\n",
      "Epoch 13/15\n",
      "800000/800000 [==============================] - 17s 21us/step - loss: 6.5157 - mae: 6.5157\n",
      "Epoch 14/15\n",
      "800000/800000 [==============================] - 17s 21us/step - loss: 6.3991 - mae: 6.3991\n",
      "Epoch 15/15\n",
      "800000/800000 [==============================] - 16s 20us/step - loss: 6.2276 - mae: 6.2276\n",
      "Test loss: 0.4954544544219971\n",
      "Test score: 49.545443534851074\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.4955  \u001b[0m | \u001b[0m 0.09313 \u001b[0m | \u001b[0m 0.003521\u001b[0m |\n",
      "Epoch 1/15\n",
      "800000/800000 [==============================] - 18s 22us/step - loss: 48.6618 - mae: 48.6619\n",
      "Epoch 2/15\n",
      "800000/800000 [==============================] - 17s 21us/step - loss: 21.5330 - mae: 21.5330\n",
      "Epoch 3/15\n",
      "800000/800000 [==============================] - 17s 21us/step - loss: 15.5577 - mae: 15.5576\n",
      "Epoch 4/15\n",
      "800000/800000 [==============================] - 17s 21us/step - loss: 13.2407 - mae: 13.2407\n",
      "Epoch 5/15\n",
      "800000/800000 [==============================] - 17s 21us/step - loss: 11.9996 - mae: 11.9996\n",
      "Epoch 6/15\n",
      "800000/800000 [==============================] - 17s 21us/step - loss: 11.1382 - mae: 11.1382ETA: \n",
      "Epoch 7/15\n",
      "800000/800000 [==============================] - 17s 21us/step - loss: 10.5428 - mae: 10.5428\n",
      "Epoch 8/15\n",
      "800000/800000 [==============================] - 16s 21us/step - loss: 10.1098 - mae: 10.1098\n",
      "Epoch 9/15\n",
      "800000/800000 [==============================] - 17s 21us/step - loss: 9.7449 - mae: 9.7449\n",
      "Epoch 10/15\n",
      "800000/800000 [==============================] - 16s 21us/step - loss: 9.3917 - mae: 9.3917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/15\n",
      "800000/800000 [==============================] - 16s 20us/step - loss: 9.1740 - mae: 9.1740\n",
      "Epoch 12/15\n",
      "800000/800000 [==============================] - 17s 21us/step - loss: 9.0138 - mae: 9.0138\n",
      "Epoch 13/15\n",
      "800000/800000 [==============================] - 16s 21us/step - loss: 8.7980 - mae: 8.7980\n",
      "Epoch 14/15\n",
      "800000/800000 [==============================] - 17s 21us/step - loss: 8.6158 - mae: 8.6158\n",
      "Epoch 15/15\n",
      "800000/800000 [==============================] - 16s 20us/step - loss: 8.4482 - mae: 8.4482\n",
      "Test loss: 0.6098661899566651\n",
      "Test score: 60.986618995666504\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.6099  \u001b[0m | \u001b[0m 0.1984  \u001b[0m | \u001b[0m 0.005434\u001b[0m |\n",
      "Epoch 1/15\n",
      "800000/800000 [==============================] - 18s 22us/step - loss: 50.0551 - mae: 50.0550\n",
      "Epoch 2/15\n",
      "800000/800000 [==============================] - 16s 21us/step - loss: 23.7387 - mae: 23.7387\n",
      "Epoch 3/15\n",
      "800000/800000 [==============================] - 17s 21us/step - loss: 16.9208 - mae: 16.9208\n",
      "Epoch 4/15\n",
      "800000/800000 [==============================] - 16s 20us/step - loss: 14.4076 - mae: 14.4076\n",
      "Epoch 5/15\n",
      "800000/800000 [==============================] - 16s 21us/step - loss: 12.9328 - mae: 12.9328\n",
      "Epoch 6/15\n",
      "800000/800000 [==============================] - 16s 21us/step - loss: 11.9848 - mae: 11.9848\n",
      "Epoch 7/15\n",
      "800000/800000 [==============================] - 16s 21us/step - loss: 11.3647 - mae: 11.3647\n",
      "Epoch 8/15\n",
      "800000/800000 [==============================] - 16s 21us/step - loss: 10.8669 - mae: 10.8669\n",
      "Epoch 9/15\n",
      "800000/800000 [==============================] - 16s 21us/step - loss: 10.3813 - mae: 10.3813\n",
      "Epoch 10/15\n",
      "800000/800000 [==============================] - 17s 21us/step - loss: 10.0929 - mae: 10.0929\n",
      "Epoch 11/15\n",
      "800000/800000 [==============================] - 16s 21us/step - loss: 9.7993 - mae: 9.7993\n",
      "Epoch 12/15\n",
      "800000/800000 [==============================] - 17s 21us/step - loss: 9.6011 - mae: 9.6012\n",
      "Epoch 13/15\n",
      "800000/800000 [==============================] - 16s 20us/step - loss: 9.4248 - mae: 9.4248\n",
      "Epoch 14/15\n",
      "800000/800000 [==============================] - 16s 20us/step - loss: 9.2020 - mae: 9.2020\n",
      "Epoch 15/15\n",
      "800000/800000 [==============================] - 16s 20us/step - loss: 9.0259 - mae: 9.0259\n",
      "Test loss: 0.725061559677124\n",
      "Test score: 72.50615501403809\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.7251  \u001b[0m | \u001b[0m 0.2096  \u001b[0m | \u001b[0m 0.006884\u001b[0m |\n",
      "Epoch 1/15\n",
      "800000/800000 [==============================] - 18s 22us/step - loss: 54.2395 - mae: 54.2395\n",
      "Epoch 2/15\n",
      "800000/800000 [==============================] - 16s 21us/step - loss: 23.7833 - mae: 23.7833\n",
      "Epoch 3/15\n",
      "800000/800000 [==============================] - 17s 21us/step - loss: 15.6247 - mae: 15.6247\n",
      "Epoch 4/15\n",
      "800000/800000 [==============================] - 17s 21us/step - loss: 12.6960 - mae: 12.6960\n",
      "Epoch 5/15\n",
      "800000/800000 [==============================] - 16s 21us/step - loss: 11.3292 - mae: 11.3292\n",
      "Epoch 6/15\n",
      "800000/800000 [==============================] - 16s 21us/step - loss: 10.3487 - mae: 10.3487\n",
      "Epoch 7/15\n",
      "800000/800000 [==============================] - 16s 21us/step - loss: 9.5999 - mae: 9.5999\n",
      "Epoch 8/15\n",
      "800000/800000 [==============================] - 16s 20us/step - loss: 9.1169 - mae: 9.1169\n",
      "Epoch 9/15\n",
      "800000/800000 [==============================] - 16s 20us/step - loss: 8.7020 - mae: 8.7020\n",
      "Epoch 10/15\n",
      "800000/800000 [==============================] - 16s 21us/step - loss: 8.3618 - mae: 8.3618\n",
      "Epoch 11/15\n",
      "800000/800000 [==============================] - 16s 21us/step - loss: 8.0730 - mae: 8.0730\n",
      "Epoch 12/15\n",
      "800000/800000 [==============================] - 16s 20us/step - loss: 7.8586 - mae: 7.8586 6s \n",
      "Epoch 13/15\n",
      "800000/800000 [==============================] - 16s 21us/step - loss: 7.5754 - mae: 7.5754\n",
      "Epoch 14/15\n",
      "800000/800000 [==============================] - 16s 21us/step - loss: 7.3691 - mae: 7.3691\n",
      "Epoch 15/15\n",
      "800000/800000 [==============================] - 16s 21us/step - loss: 7.2835 - mae: 7.2835\n",
      "Test loss: 0.7013539791107177\n",
      "Test score: 70.13539838790894\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.7014  \u001b[0m | \u001b[0m 0.1022  \u001b[0m | \u001b[0m 0.008793\u001b[0m |\n",
      "Epoch 1/15\n",
      "800000/800000 [==============================] - 18s 22us/step - loss: 47.9183 - mae: 47.9183 2s - loss: 50.4640 - mae: - ETA: 1s - l\n",
      "Epoch 2/15\n",
      "800000/800000 [==============================] - 16s 20us/step - loss: 18.6990 - mae: 18.6990\n",
      "Epoch 3/15\n",
      "800000/800000 [==============================] - 16s 20us/step - loss: 12.1054 - mae: 12.1054\n",
      "Epoch 4/15\n",
      "800000/800000 [==============================] - 16s 20us/step - loss: 9.8355 - mae: 9.8355 1s - loss: 9\n",
      "Epoch 5/15\n",
      "800000/800000 [==============================] - 16s 20us/step - loss: 8.5847 - mae: 8.5847\n",
      "Epoch 6/15\n",
      "800000/800000 [==============================] - 17s 21us/step - loss: 7.7641 - mae: 7.7641 0s - loss: 7.7629 - mae: 7.76\n",
      "Epoch 7/15\n",
      "800000/800000 [==============================] - 16s 20us/step - loss: 7.2515 - mae: 7.2515\n",
      "Epoch 8/15\n",
      "800000/800000 [==============================] - 16s 20us/step - loss: 6.8579 - mae: 6.8579\n",
      "Epoch 9/15\n",
      "800000/800000 [==============================] - 16s 20us/step - loss: 6.5162 - mae: 6.5162\n",
      "Epoch 10/15\n",
      "800000/800000 [==============================] - 16s 20us/step - loss: 6.2741 - mae: 6.2741\n",
      "Epoch 11/15\n",
      "800000/800000 [==============================] - 16s 20us/step - loss: 6.0396 - mae: 6.0396\n",
      "Epoch 12/15\n",
      "800000/800000 [==============================] - 17s 21us/step - loss: 5.7845 - mae: 5.7845\n",
      "Epoch 13/15\n",
      "800000/800000 [==============================] - 17s 21us/step - loss: 5.5938 - mae: 5.5938\n",
      "Epoch 14/15\n",
      "800000/800000 [==============================] - 17s 21us/step - loss: 5.4797 - mae: 5.4797\n",
      "Epoch 15/15\n",
      "800000/800000 [==============================] - 16s 20us/step - loss: 5.3603 - mae: 5.3603 1s \n",
      "Test loss: 0.5498446464538574\n",
      "Test score: 54.98446464538574\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.5498  \u001b[0m | \u001b[0m 0.01369 \u001b[0m | \u001b[0m 0.006738\u001b[0m |\n",
      "Epoch 1/15\n",
      "800000/800000 [==============================] - 18s 23us/step - loss: 48.8515 - mae: 48.8515\n",
      "Epoch 2/15\n",
      "800000/800000 [==============================] - 17s 21us/step - loss: 22.4080 - mae: 22.4080\n",
      "Epoch 3/15\n",
      "800000/800000 [==============================] - 17s 21us/step - loss: 16.3726 - mae: 16.3726\n",
      "Epoch 4/15\n",
      "800000/800000 [==============================] - 16s 21us/step - loss: 13.8316 - mae: 13.8316\n",
      "Epoch 5/15\n",
      "800000/800000 [==============================] - 17s 21us/step - loss: 12.5166 - mae: 12.5166 1s -\n",
      "Epoch 6/15\n",
      "800000/800000 [==============================] - 16s 21us/step - loss: 11.5879 - mae: 11.5879\n",
      "Epoch 7/15\n",
      "800000/800000 [==============================] - 17s 21us/step - loss: 10.9414 - mae: 10.9414\n",
      "Epoch 8/15\n",
      "800000/800000 [==============================] - 17s 21us/step - loss: 10.4503 - mae: 10.4503\n",
      "Epoch 9/15\n",
      "800000/800000 [==============================] - 17s 21us/step - loss: 10.0016 - mae: 10.0016 0s - loss: 10.0074 - mae: 10\n",
      "Epoch 10/15\n",
      "800000/800000 [==============================] - 17s 21us/step - loss: 9.7074 - mae: 9.7074\n",
      "Epoch 11/15\n",
      "800000/800000 [==============================] - 17s 21us/step - loss: 9.4575 - mae: 9.4575 1s \n",
      "Epoch 12/15\n",
      "800000/800000 [==============================] - 16s 21us/step - loss: 9.1730 - mae: 9.1730 \n",
      "Epoch 13/15\n",
      "800000/800000 [==============================] - 17s 21us/step - loss: 8.9831 - mae: 8.9831\n",
      "Epoch 14/15\n",
      "800000/800000 [==============================] - 17s 21us/step - loss: 8.7651 - mae: 8.7651 6\n",
      "Epoch 15/15\n",
      "800000/800000 [==============================] - 17s 21us/step - loss: 8.6273 - mae: 8.6273\n",
      "Test loss: 0.5961491584777832\n",
      "Test score: 59.61491298675537\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.5961  \u001b[0m | \u001b[0m 0.2087  \u001b[0m | \u001b[0m 0.005631\u001b[0m |\n",
      "Epoch 1/15\n",
      "800000/800000 [==============================] - 18s 23us/step - loss: 48.7353 - mae: 48.7353\n",
      "Epoch 2/15\n",
      "800000/800000 [==============================] - 17s 21us/step - loss: 18.1522 - mae: 18.1522\n",
      "Epoch 3/15\n",
      "800000/800000 [==============================] - 17s 21us/step - loss: 11.9699 - mae: 11.9699\n",
      "Epoch 4/15\n",
      "800000/800000 [==============================] - 17s 21us/step - loss: 9.8210 - mae: 9.8210\n",
      "Epoch 5/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800000/800000 [==============================] - 16s 21us/step - loss: 8.6913 - mae: 8.6913\n",
      "Epoch 6/15\n",
      "800000/800000 [==============================] - 17s 21us/step - loss: 7.9203 - mae: 7.9203\n",
      "Epoch 7/15\n",
      "800000/800000 [==============================] - 16s 21us/step - loss: 7.4526 - mae: 7.4526 1s - \n",
      "Epoch 8/15\n",
      "800000/800000 [==============================] - 16s 21us/step - loss: 7.0293 - mae: 7.0293\n",
      "Epoch 9/15\n",
      "800000/800000 [==============================] - 17s 21us/step - loss: 6.7256 - mae: 6.7256\n",
      "Epoch 10/15\n",
      "800000/800000 [==============================] - 17s 21us/step - loss: 6.4903 - mae: 6.4903\n",
      "Epoch 11/15\n",
      "800000/800000 [==============================] - 17s 21us/step - loss: 6.2259 - mae: 6.2259\n",
      "Epoch 12/15\n",
      "800000/800000 [==============================] - 16s 20us/step - loss: 6.0463 - mae: 6.0463 1s - \n",
      "Epoch 13/15\n",
      "800000/800000 [==============================] - 17s 21us/step - loss: 5.8779 - mae: 5.8779 2s - loss: 5.8862 - mae: \n",
      "Epoch 14/15\n",
      "800000/800000 [==============================] - 16s 21us/step - loss: 5.7574 - mae: 5.7574\n",
      "Epoch 15/15\n",
      "800000/800000 [==============================] - 17s 21us/step - loss: 5.6447 - mae: 5.6447\n",
      "Test loss: 0.4439279556274414\n",
      "Test score: 44.39279651641846\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.4439  \u001b[0m | \u001b[0m 0.07019 \u001b[0m | \u001b[0m 0.002061\u001b[0m |\n",
      "Epoch 1/15\n",
      "800000/800000 [==============================] - 18s 22us/step - loss: 50.5817 - mae: 50.5817\n",
      "Epoch 2/15\n",
      "800000/800000 [==============================] - 16s 21us/step - loss: 32.0975 - mae: 32.0975\n",
      "Epoch 3/15\n",
      "800000/800000 [==============================] - 17s 21us/step - loss: 26.4678 - mae: 26.4678 0s - loss: 26.4815 - mae: 26\n",
      "Epoch 4/15\n",
      "800000/800000 [==============================] - 16s 21us/step - loss: 23.9575 - mae: 23.9575\n",
      "Epoch 5/15\n",
      "800000/800000 [==============================] - 17s 21us/step - loss: 22.2650 - mae: 22.2650 1s - lo\n",
      "Epoch 6/15\n",
      "800000/800000 [==============================] - 17s 21us/step - loss: 21.1911 - mae: 21.1911 4s - l - \n",
      "Epoch 7/15\n",
      "800000/800000 [==============================] - 17s 21us/step - loss: 20.2074 - mae: 20.2074 1s - loss: 20\n",
      "Epoch 8/15\n",
      "800000/800000 [==============================] - 16s 21us/step - loss: 19.4931 - mae: 19.4931 0s - loss: 19.4935 - mae: 19.49\n",
      "Epoch 9/15\n",
      "800000/800000 [==============================] - 16s 20us/step - loss: 18.8577 - mae: 18.8577\n",
      "Epoch 10/15\n",
      "800000/800000 [==============================] - 16s 21us/step - loss: 18.3789 - mae: 18.3789\n",
      "Epoch 11/15\n",
      "800000/800000 [==============================] - 16s 20us/step - loss: 18.0665 - mae: 18.0665\n",
      "Epoch 12/15\n",
      "800000/800000 [==============================] - 16s 20us/step - loss: 17.5846 - mae: 17.5846 9s - loss: 17.7253 - -  - ETA: 3s - loss: 17\n",
      "Epoch 13/15\n",
      "800000/800000 [==============================] - 16s 21us/step - loss: 17.3280 - mae: 17.3280\n",
      "Epoch 14/15\n",
      "800000/800000 [==============================] - 16s 21us/step - loss: 17.1429 - mae: 17.1429\n",
      "Epoch 15/15\n",
      "800000/800000 [==============================] - 16s 20us/step - loss: 16.8005 - mae: 16.8005\n",
      "Test loss: 1.1875377655029298\n",
      "Test score: 118.75377178192139\n",
      "| \u001b[95m 11      \u001b[0m | \u001b[95m 1.188   \u001b[0m | \u001b[95m 0.5     \u001b[0m | \u001b[95m 0.01    \u001b[0m |\n",
      "Epoch 1/15\n",
      "800000/800000 [==============================] - 18s 23us/step - loss: 52.5098 - mae: 52.5098\n",
      "Epoch 2/15\n",
      "800000/800000 [==============================] - 17s 21us/step - loss: 31.5395 - mae: 31.5395\n",
      "Epoch 3/15\n",
      "800000/800000 [==============================] - 17s 21us/step - loss: 25.4946 - mae: 25.4946\n",
      "Epoch 4/15\n",
      "800000/800000 [==============================] - 16s 20us/step - loss: 22.5430 - mae: 22.5430\n",
      "Epoch 5/15\n",
      "800000/800000 [==============================] - 16s 20us/step - loss: 20.8541 - mae: 20.8541\n",
      "Epoch 6/15\n",
      "800000/800000 [==============================] - 16s 20us/step - loss: 19.4790 - mae: 19.4790\n",
      "Epoch 7/15\n",
      "800000/800000 [==============================] - 16s 20us/step - loss: 18.5683 - mae: 18.5683\n",
      "Epoch 8/15\n",
      "800000/800000 [==============================] - 16s 20us/step - loss: 17.7978 - mae: 17.7977\n",
      "Epoch 9/15\n",
      "800000/800000 [==============================] - 16s 20us/step - loss: 17.2102 - mae: 17.2102\n",
      "Epoch 10/15\n",
      "800000/800000 [==============================] - 16s 20us/step - loss: 16.7212 - mae: 16.7212\n",
      "Epoch 11/15\n",
      "800000/800000 [==============================] - 16s 20us/step - loss: 16.2730 - mae: 16.2730\n",
      "Epoch 12/15\n",
      "800000/800000 [==============================] - 16s 20us/step - loss: 15.9938 - mae: 15.9938 2s - loss: 16.0086 - mae: 16.00 - ETA: 2s  - ETA: 0s - loss: 16.0045 \n",
      "Epoch 13/15\n",
      "800000/800000 [==============================] - 16s 20us/step - loss: 15.5699 - mae: 15.5699\n",
      "Epoch 14/15\n",
      "800000/800000 [==============================] - 17s 21us/step - loss: 15.4022 - mae: 15.4022\n",
      "Epoch 15/15\n",
      "800000/800000 [==============================] - 17s 21us/step - loss: 15.1619 - mae: 15.1619\n",
      "Test loss: 1.0244808197021484\n",
      "Test score: 102.44807624816895\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 1.024   \u001b[0m | \u001b[0m 0.4457  \u001b[0m | \u001b[0m 0.01    \u001b[0m |\n",
      "Epoch 1/15\n",
      "800000/800000 [==============================] - 18s 22us/step - loss: 55.7158 - mae: 55.7158\n",
      "Epoch 2/15\n",
      "800000/800000 [==============================] - 16s 20us/step - loss: 32.6053 - mae: 32.6053\n",
      "Epoch 3/15\n",
      "800000/800000 [==============================] - 16s 20us/step - loss: 23.8810 - mae: 23.8810 1s - loss\n",
      "Epoch 4/15\n",
      "800000/800000 [==============================] - 16s 21us/step - loss: 20.4893 - mae: 20.4893\n",
      "Epoch 5/15\n",
      "800000/800000 [==============================] - 16s 20us/step - loss: 18.5880 - mae: 18.5880 2s - loss: 18.7229 -  - ETA: 1s - loss\n",
      "Epoch 6/15\n",
      "800000/800000 [==============================] - 16s 20us/step - loss: 17.2318 - mae: 17.2319\n",
      "Epoch 7/15\n",
      "800000/800000 [==============================] - 17s 21us/step - loss: 16.3234 - mae: 16.3234\n",
      "Epoch 8/15\n",
      "800000/800000 [==============================] - 16s 20us/step - loss: 15.6760 - mae: 15.6760 3s - los - ETA: 1s - lo - ETA: 0s - loss: 15.6792 - mae: 15.6\n",
      "Epoch 9/15\n",
      "800000/800000 [==============================] - 16s 20us/step - loss: 15.1242 - mae: 15.1242\n",
      "Epoch 10/15\n",
      "800000/800000 [==============================] - 16s 21us/step - loss: 14.6278 - mae: 14.6278\n",
      "Epoch 11/15\n",
      "800000/800000 [==============================] - 16s 20us/step - loss: 14.1940 - mae: 14.1940\n",
      "Epoch 12/15\n",
      "800000/800000 [==============================] - 16s 20us/step - loss: 13.8437 - mae: 13.8437\n",
      "Epoch 13/15\n",
      "800000/800000 [==============================] - 16s 20us/step - loss: 13.6118 - mae: 13.6118\n",
      "Epoch 14/15\n",
      "800000/800000 [==============================] - 16s 20us/step - loss: 13.3121 - mae: 13.3121\n",
      "Epoch 15/15\n",
      "800000/800000 [==============================] - 16s 20us/step - loss: 13.0316 - mae: 13.0316\n",
      "Test loss: 1.0195449829101562\n",
      "Test score: 101.95449829101562\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 1.02    \u001b[0m | \u001b[0m 0.3765  \u001b[0m | \u001b[0m 0.01    \u001b[0m |\n",
      "Epoch 1/15\n",
      "800000/800000 [==============================] - 18s 22us/step - loss: 55.1744 - mae: 55.1744 0s - loss: 55.8424 \n",
      "Epoch 2/15\n",
      "800000/800000 [==============================] - 17s 21us/step - loss: 30.3809 - mae: 30.3809\n",
      "Epoch 3/15\n",
      "800000/800000 [==============================] - 16s 21us/step - loss: 21.4596 - mae: 21.4596 3s - loss: 2\n",
      "Epoch 4/15\n",
      "800000/800000 [==============================] - 17s 21us/step - loss: 18.2168 - mae: 18.2168\n",
      "Epoch 5/15\n",
      "800000/800000 [==============================] - 17s 21us/step - loss: 16.5139 - mae: 16.5139\n",
      "Epoch 6/15\n",
      "800000/800000 [==============================] - 17s 21us/step - loss: 15.4170 - mae: 15.4170\n",
      "Epoch 7/15\n",
      "800000/800000 [==============================] - 16s 21us/step - loss: 14.5444 - mae: 14.5444 1s - loss: \n",
      "Epoch 8/15\n",
      "800000/800000 [==============================] - 17s 21us/step - loss: 13.9464 - mae: 13.9464\n",
      "Epoch 9/15\n",
      "800000/800000 [==============================] - 17s 21us/step - loss: 13.4388 - mae: 13.4388\n",
      "Epoch 10/15\n",
      "800000/800000 [==============================] - 17s 21us/step - loss: 12.9939 - mae: 12.9939 0s - loss: 12.9938 - mae: 12.993\n",
      "Epoch 11/15\n",
      "800000/800000 [==============================] - 17s 21us/step - loss: 12.5634 - mae: 12.5634\n",
      "Epoch 12/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800000/800000 [==============================] - 17s 21us/step - loss: 12.2846 - mae: 12.2846 1s - loss - ETA: 0s - loss: 12.2836 - mae: 12.283\n",
      "Epoch 13/15\n",
      "800000/800000 [==============================] - 16s 20us/step - loss: 12.0486 - mae: 12.0486\n",
      "Epoch 14/15\n",
      "800000/800000 [==============================] - 17s 21us/step - loss: 11.8076 - mae: 11.8076\n",
      "Epoch 15/15\n",
      "800000/800000 [==============================] - 17s 21us/step - loss: 11.6397 - mae: 11.6397\n",
      "Test loss: 0.7667818069458008\n",
      "Test score: 76.67818021774292\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.7668  \u001b[0m | \u001b[0m 0.3136  \u001b[0m | \u001b[0m 0.01    \u001b[0m |\n"
     ]
    }
   ],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "# Bounded region of parameter space\n",
    "pbounds = {'dropout_rate': (0.0, 0.1), 'lr': (1e-4, 1e-2)}\n",
    "\n",
    "bayes_optimizer = BayesianOptimization(\n",
    "    f=fit_with_partial,\n",
    "    pbounds=pbounds,\n",
    "    verbose=2,  # verbose = 1 prints only when a maximum is observed, verbose = 0 is silent\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "bayes_optimizer.maximize(init_points=10, n_iter=10,)\n",
    "for i, res in enumerate(bayes_optimizer.res):\n",
    "    print(\"Iteration {}: \\n\\t{}\".format(i, res))\n",
    "\n",
    "print(bayes_optimizer.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-fe09077de656>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel11\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel11\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\py37\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py37\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    150\u001b[0m                 \u001b[0mbatch_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'batch'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstep_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'size'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'begin'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 152\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfit_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py37\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3740\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3742\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py37\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1080\u001b[0m     \"\"\"\n\u001b[1;32m-> 1081\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1082\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1083\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py37\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1121\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py37\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py37\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py37\\lib\\site-packages\\tensorflow_core\\python\\eager\\core.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, message, code)\u001b[0m\n\u001b[0;32m     37\u001b[0m   \u001b[1;34m\"\"\"Exception class to handle not ok Status.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m   \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m     \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model11 = build_model()\n",
    "model11.fit(train_X, train_Y, epochs=100, batch_size=1000, validation_split = 0.05, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py37] *",
   "language": "python",
   "name": "conda-env-py37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
