{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "import numpy as np\n",
    "warnings.filterwarnings('ignore')\n",
    "train = pd.read_csv('trains.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "for col in train.columns:\n",
    "    col_type = train[col].dtypes\n",
    "    min1 = train[col].min()\n",
    "    max1 = train[col].max()\n",
    "    if str(col_type)[:3] == 'int':\n",
    "        train[col] = train[col].astype(np.int16)\n",
    "    else:\n",
    "        if min1 > np.finfo(np.float16).min and max1 < np.finfo(np.float16).max:\n",
    "            train[col] = train[col].astype(np.float16)\n",
    "        elif min1 > np.finfo(np.float32).min and max1 < np.finfo(np.float32).max:\n",
    "            train[col] = train[col].astype(np.float32)\n",
    "        else:\n",
    "            train[col] = train[col].astype(np.float64)\n",
    "\n",
    "#독립변수와 종속변수를 분리합니다.\n",
    "train_X = train.iloc[:,4:]\n",
    "train_Y = train.iloc[:,0:4]\n",
    "test_X = test.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 769500 samples, validate on 40500 samples\n",
      "Epoch 1/100\n",
      "769500/769500 [==============================] - 24s 32us/step - loss: 45.5450 - mae: 45.5449 - val_loss: 39.3852 - val_mae: 39.3852\n",
      "Epoch 2/100\n",
      "769500/769500 [==============================] - 22s 28us/step - loss: 17.0392 - mae: 17.0392 - val_loss: 26.1285 - val_mae: 26.1285\n",
      "Epoch 3/100\n",
      "769500/769500 [==============================] - 22s 29us/step - loss: 11.6399 - mae: 11.6399 - val_loss: 19.5025 - val_mae: 19.5025\n",
      "Epoch 4/100\n",
      "769500/769500 [==============================] - 22s 29us/step - loss: 9.6813 - mae: 9.6813 - val_loss: 22.2903 - val_mae: 22.2903\n",
      "Epoch 5/100\n",
      "769500/769500 [==============================] - 22s 29us/step - loss: 8.5432 - mae: 8.5432 - val_loss: 22.4035 - val_mae: 22.4035\n",
      "Epoch 6/100\n",
      "769500/769500 [==============================] - 22s 29us/step - loss: 7.8464 - mae: 7.8464 - val_loss: 20.0418 - val_mae: 20.0418\n",
      "Epoch 7/100\n",
      "769500/769500 [==============================] - 22s 29us/step - loss: 7.2823 - mae: 7.2823 - val_loss: 18.4107 - val_mae: 18.4107\n",
      "Epoch 8/100\n",
      "769500/769500 [==============================] - 22s 29us/step - loss: 6.8389 - mae: 6.8389 - val_loss: 17.9045 - val_mae: 17.9045\n",
      "Epoch 9/100\n",
      "769500/769500 [==============================] - 22s 29us/step - loss: 6.5268 - mae: 6.5268 - val_loss: 15.9452 - val_mae: 15.9452\n",
      "Epoch 10/100\n",
      "769500/769500 [==============================] - 22s 29us/step - loss: 6.1833 - mae: 6.1833 - val_loss: 17.2860 - val_mae: 17.2860\n",
      "Epoch 11/100\n",
      "769500/769500 [==============================] - 22s 29us/step - loss: 6.0135 - mae: 6.0135 - val_loss: 16.7356 - val_mae: 16.7356\n",
      "Epoch 12/100\n",
      "769500/769500 [==============================] - 22s 29us/step - loss: 5.7281 - mae: 5.7281 - val_loss: 16.3066 - val_mae: 16.3066\n",
      "Epoch 13/100\n",
      "769500/769500 [==============================] - 22s 29us/step - loss: 5.5793 - mae: 5.5793 - val_loss: 14.3988 - val_mae: 14.3988\n",
      "Epoch 14/100\n",
      "769500/769500 [==============================] - 22s 29us/step - loss: 5.4160 - mae: 5.4160 - val_loss: 16.6154 - val_mae: 16.6154\n",
      "Epoch 15/100\n",
      "769500/769500 [==============================] - 22s 29us/step - loss: 5.2563 - mae: 5.2563 - val_loss: 15.5077 - val_mae: 15.5077\n",
      "Epoch 16/100\n",
      "769500/769500 [==============================] - 22s 29us/step - loss: 5.1743 - mae: 5.1743 - val_loss: 16.6993 - val_mae: 16.6993\n",
      "Epoch 17/100\n",
      "769500/769500 [==============================] - 22s 29us/step - loss: 4.9928 - mae: 4.9928 - val_loss: 14.9851 - val_mae: 14.9851\n",
      "Epoch 18/100\n",
      "769500/769500 [==============================] - 22s 29us/step - loss: 4.8987 - mae: 4.8987 - val_loss: 14.3122 - val_mae: 14.3122\n",
      "Epoch 19/100\n",
      "769500/769500 [==============================] - 22s 29us/step - loss: 4.8064 - mae: 4.8064 - val_loss: 14.5887 - val_mae: 14.5887\n",
      "Epoch 20/100\n",
      "769500/769500 [==============================] - 22s 29us/step - loss: 4.7484 - mae: 4.7484 - val_loss: 15.0768 - val_mae: 15.0768\n",
      "Epoch 21/100\n",
      "769500/769500 [==============================] - 22s 29us/step - loss: 4.6555 - mae: 4.6555 - val_loss: 14.4506 - val_mae: 14.4506\n",
      "Epoch 22/100\n",
      "769500/769500 [==============================] - 22s 29us/step - loss: 4.5740 - mae: 4.5740 - val_loss: 14.3146 - val_mae: 14.3145\n",
      "Epoch 23/100\n",
      "769500/769500 [==============================] - 22s 28us/step - loss: 4.5037 - mae: 4.5037 - val_loss: 13.1940 - val_mae: 13.1940\n",
      "Epoch 24/100\n",
      "769500/769500 [==============================] - 22s 28us/step - loss: 4.4341 - mae: 4.4341 - val_loss: 13.9113 - val_mae: 13.9113\n",
      "Epoch 25/100\n",
      "769500/769500 [==============================] - 22s 29us/step - loss: 4.3630 - mae: 4.3630 - val_loss: 12.3703 - val_mae: 12.3703\n",
      "Epoch 26/100\n",
      "769500/769500 [==============================] - 22s 29us/step - loss: 4.3106 - mae: 4.3106 - val_loss: 12.1622 - val_mae: 12.1622\n",
      "Epoch 27/100\n",
      "769500/769500 [==============================] - 22s 29us/step - loss: 4.2564 - mae: 4.2564 - val_loss: 13.5432 - val_mae: 13.5432\n",
      "Epoch 28/100\n",
      "769500/769500 [==============================] - 22s 29us/step - loss: 4.2125 - mae: 4.2125 - val_loss: 12.3037 - val_mae: 12.3037\n",
      "Epoch 29/100\n",
      "769500/769500 [==============================] - 22s 29us/step - loss: 4.1377 - mae: 4.1377 - val_loss: 12.0568 - val_mae: 12.0569\n",
      "Epoch 30/100\n",
      "769500/769500 [==============================] - 22s 29us/step - loss: 4.1132 - mae: 4.1132 - val_loss: 11.4012 - val_mae: 11.4012\n",
      "Epoch 31/100\n",
      "769500/769500 [==============================] - 22s 29us/step - loss: 4.0516 - mae: 4.0516 - val_loss: 13.1061 - val_mae: 13.1061\n",
      "Epoch 32/100\n",
      "769500/769500 [==============================] - 23s 29us/step - loss: 4.0321 - mae: 4.0321 - val_loss: 13.6457 - val_mae: 13.6457\n",
      "Epoch 33/100\n",
      "769500/769500 [==============================] - 23s 29us/step - loss: 3.9873 - mae: 3.9873 - val_loss: 14.3954 - val_mae: 14.3954\n",
      "Epoch 34/100\n",
      "769500/769500 [==============================] - 23s 30us/step - loss: 3.9852 - mae: 3.9852 - val_loss: 14.1605 - val_mae: 14.1605\n",
      "Epoch 35/100\n",
      "769500/769500 [==============================] - 22s 28us/step - loss: 3.8921 - mae: 3.8921 - val_loss: 14.0741 - val_mae: 14.0741\n",
      "Epoch 36/100\n",
      "769500/769500 [==============================] - 22s 28us/step - loss: 3.8978 - mae: 3.8978 - val_loss: 14.3546 - val_mae: 14.3546\n",
      "Epoch 37/100\n",
      "769500/769500 [==============================] - 22s 29us/step - loss: 3.8517 - mae: 3.8517 - val_loss: 11.5218 - val_mae: 11.5218\n",
      "Epoch 38/100\n",
      "769500/769500 [==============================] - 22s 29us/step - loss: 3.8094 - mae: 3.8094 - val_loss: 12.5934 - val_mae: 12.5934\n",
      "Epoch 39/100\n",
      "769500/769500 [==============================] - 22s 29us/step - loss: 3.7855 - mae: 3.7855 - val_loss: 13.9563 - val_mae: 13.9563\n",
      "Epoch 40/100\n",
      "769500/769500 [==============================] - 22s 29us/step - loss: 3.7596 - mae: 3.7596 - val_loss: 14.5341 - val_mae: 14.5341\n",
      "Epoch 41/100\n",
      "769500/769500 [==============================] - 22s 29us/step - loss: 3.7311 - mae: 3.7311 - val_loss: 12.9098 - val_mae: 12.9098\n",
      "Epoch 42/100\n",
      "769500/769500 [==============================] - 22s 28us/step - loss: 3.7066 - mae: 3.7066 - val_loss: 12.9579 - val_mae: 12.9579\n",
      "Epoch 43/100\n",
      "769500/769500 [==============================] - 22s 28us/step - loss: 3.6929 - mae: 3.6929 - val_loss: 12.5915 - val_mae: 12.5915\n",
      "Epoch 44/100\n",
      "769500/769500 [==============================] - 22s 29us/step - loss: 3.6614 - mae: 3.6614 - val_loss: 13.2335 - val_mae: 13.2335\n",
      "Epoch 45/100\n",
      "769500/769500 [==============================] - 22s 29us/step - loss: 3.6457 - mae: 3.6457 - val_loss: 12.3064 - val_mae: 12.3064\n",
      "Epoch 46/100\n",
      "769500/769500 [==============================] - 22s 29us/step - loss: 3.6357 - mae: 3.6357 - val_loss: 11.6591 - val_mae: 11.6591\n",
      "Epoch 47/100\n",
      "769500/769500 [==============================] - 22s 29us/step - loss: 3.5684 - mae: 3.5684 - val_loss: 13.7603 - val_mae: 13.7603\n",
      "Epoch 48/100\n",
      "769500/769500 [==============================] - 22s 29us/step - loss: 3.5608 - mae: 3.5607 - val_loss: 12.1677 - val_mae: 12.1677\n",
      "Epoch 49/100\n",
      "769500/769500 [==============================] - 23s 29us/step - loss: 3.5432 - mae: 3.5432 - val_loss: 11.6274 - val_mae: 11.6274\n",
      "Epoch 50/100\n",
      "769500/769500 [==============================] - 22s 29us/step - loss: 3.5084 - mae: 3.5084 - val_loss: 13.4973 - val_mae: 13.4973\n",
      "Epoch 51/100\n",
      "769500/769500 [==============================] - 22s 28us/step - loss: 3.4989 - mae: 3.4989 - val_loss: 11.8417 - val_mae: 11.8417\n",
      "Epoch 52/100\n",
      "769500/769500 [==============================] - 22s 28us/step - loss: 3.4910 - mae: 3.4910 - val_loss: 12.1793 - val_mae: 12.1793\n",
      "Epoch 53/100\n",
      "769500/769500 [==============================] - 22s 28us/step - loss: 3.4735 - mae: 3.4735 - val_loss: 11.8344 - val_mae: 11.8344\n",
      "Epoch 54/100\n",
      "769500/769500 [==============================] - 22s 28us/step - loss: 3.4536 - mae: 3.4536 - val_loss: 12.3708 - val_mae: 12.3708\n",
      "Epoch 55/100\n",
      "769500/769500 [==============================] - 22s 28us/step - loss: 3.4546 - mae: 3.4546 - val_loss: 11.0479 - val_mae: 11.0479\n",
      "Epoch 56/100\n",
      "769500/769500 [==============================] - 22s 28us/step - loss: 3.4101 - mae: 3.4101 - val_loss: 13.1373 - val_mae: 13.1373\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "769500/769500 [==============================] - 22s 28us/step - loss: 3.4085 - mae: 3.4085 - val_loss: 14.5318 - val_mae: 14.5319\n",
      "Epoch 58/100\n",
      "769500/769500 [==============================] - 22s 28us/step - loss: 3.4093 - mae: 3.4093 - val_loss: 15.9875 - val_mae: 15.9875\n",
      "Epoch 59/100\n",
      "769500/769500 [==============================] - 22s 28us/step - loss: 3.4006 - mae: 3.4006 - val_loss: 11.1511 - val_mae: 11.1511\n",
      "Epoch 60/100\n",
      "769500/769500 [==============================] - 22s 28us/step - loss: 3.3536 - mae: 3.3536 - val_loss: 13.3342 - val_mae: 13.3342\n",
      "Epoch 61/100\n",
      "769500/769500 [==============================] - 22s 28us/step - loss: 3.3310 - mae: 3.3310 - val_loss: 12.1030 - val_mae: 12.1030\n",
      "Epoch 62/100\n",
      "769500/769500 [==============================] - 22s 28us/step - loss: 3.3335 - mae: 3.3335 - val_loss: 12.1277 - val_mae: 12.1277\n",
      "Epoch 63/100\n",
      "769500/769500 [==============================] - 22s 28us/step - loss: 3.3143 - mae: 3.3143 - val_loss: 13.2827 - val_mae: 13.2827\n",
      "Epoch 64/100\n",
      "769500/769500 [==============================] - 22s 28us/step - loss: 3.3034 - mae: 3.3034 - val_loss: 11.3804 - val_mae: 11.3804\n",
      "Epoch 65/100\n",
      "769500/769500 [==============================] - 22s 28us/step - loss: 3.2991 - mae: 3.2991 - val_loss: 11.8397 - val_mae: 11.8397\n",
      "Epoch 66/100\n",
      "769500/769500 [==============================] - 22s 28us/step - loss: 3.2799 - mae: 3.2799 - val_loss: 10.7585 - val_mae: 10.7585\n",
      "Epoch 67/100\n",
      "769500/769500 [==============================] - 22s 28us/step - loss: 3.2564 - mae: 3.2564 - val_loss: 10.7945 - val_mae: 10.7945\n",
      "Epoch 68/100\n",
      "769500/769500 [==============================] - 22s 28us/step - loss: 3.2537 - mae: 3.2537 - val_loss: 11.7714 - val_mae: 11.7714\n",
      "Epoch 69/100\n",
      "769500/769500 [==============================] - 22s 28us/step - loss: 3.2296 - mae: 3.2296 - val_loss: 11.8321 - val_mae: 11.8321\n",
      "Epoch 70/100\n",
      "769500/769500 [==============================] - 22s 28us/step - loss: 3.2820 - mae: 3.2820 - val_loss: 13.1072 - val_mae: 13.1072\n",
      "Epoch 71/100\n",
      "769500/769500 [==============================] - 22s 28us/step - loss: 3.1955 - mae: 3.1955 - val_loss: 13.2495 - val_mae: 13.2495\n",
      "Epoch 72/100\n",
      "769500/769500 [==============================] - 22s 28us/step - loss: 3.2391 - mae: 3.2391 - val_loss: 12.1997 - val_mae: 12.1997\n",
      "Epoch 73/100\n",
      "769500/769500 [==============================] - 22s 28us/step - loss: 3.1927 - mae: 3.1927 - val_loss: 13.1156 - val_mae: 13.1156\n",
      "Epoch 74/100\n",
      "769500/769500 [==============================] - 22s 28us/step - loss: 3.1815 - mae: 3.1815 - val_loss: 10.0834 - val_mae: 10.0834\n",
      "Epoch 75/100\n",
      "769500/769500 [==============================] - 22s 28us/step - loss: 3.1727 - mae: 3.1727 - val_loss: 11.4146 - val_mae: 11.4146\n",
      "Epoch 76/100\n",
      "769500/769500 [==============================] - 22s 28us/step - loss: 3.1890 - mae: 3.1890 - val_loss: 12.3180 - val_mae: 12.3180\n",
      "Epoch 77/100\n",
      "769500/769500 [==============================] - 22s 28us/step - loss: 3.1462 - mae: 3.1462 - val_loss: 11.5939 - val_mae: 11.5939\n",
      "Epoch 78/100\n",
      "769500/769500 [==============================] - 22s 28us/step - loss: 3.1608 - mae: 3.1608 - val_loss: 11.8258 - val_mae: 11.8258\n",
      "Epoch 79/100\n",
      "769500/769500 [==============================] - 22s 29us/step - loss: 3.1511 - mae: 3.1511 - val_loss: 11.0993 - val_mae: 11.0993\n",
      "Epoch 80/100\n",
      "769500/769500 [==============================] - 22s 29us/step - loss: 3.1265 - mae: 3.1265 - val_loss: 11.0367 - val_mae: 11.0367\n",
      "Epoch 81/100\n",
      "769500/769500 [==============================] - 22s 29us/step - loss: 3.1427 - mae: 3.1427 - val_loss: 11.8271 - val_mae: 11.8271\n",
      "Epoch 82/100\n",
      "769500/769500 [==============================] - 22s 29us/step - loss: 3.0946 - mae: 3.0946 - val_loss: 11.7781 - val_mae: 11.7781\n",
      "Epoch 83/100\n",
      "769500/769500 [==============================] - 22s 29us/step - loss: 3.0915 - mae: 3.0915 - val_loss: 10.9501 - val_mae: 10.9501\n",
      "Epoch 84/100\n",
      "769500/769500 [==============================] - 22s 29us/step - loss: 3.0765 - mae: 3.0765 - val_loss: 11.9693 - val_mae: 11.9693\n",
      "Epoch 85/100\n",
      "769500/769500 [==============================] - 22s 28us/step - loss: 3.0726 - mae: 3.0726 - val_loss: 11.9248 - val_mae: 11.9248\n",
      "Epoch 86/100\n",
      "769500/769500 [==============================] - 22s 28us/step - loss: 3.0760 - mae: 3.0760 - val_loss: 12.7735 - val_mae: 12.7735\n",
      "Epoch 87/100\n",
      "769500/769500 [==============================] - 22s 29us/step - loss: 3.0457 - mae: 3.0457 - val_loss: 11.2580 - val_mae: 11.2580\n",
      "Epoch 88/100\n",
      "769500/769500 [==============================] - 22s 29us/step - loss: 3.0617 - mae: 3.0617 - val_loss: 12.0136 - val_mae: 12.0136\n",
      "Epoch 89/100\n",
      "769500/769500 [==============================] - 22s 29us/step - loss: 3.0589 - mae: 3.0589 - val_loss: 11.9005 - val_mae: 11.9005\n",
      "Epoch 90/100\n",
      "769500/769500 [==============================] - 22s 29us/step - loss: 3.0330 - mae: 3.0330 - val_loss: 11.9386 - val_mae: 11.9386\n",
      "Epoch 91/100\n",
      "769500/769500 [==============================] - 22s 29us/step - loss: 3.0384 - mae: 3.0384 - val_loss: 11.0254 - val_mae: 11.0254\n",
      "Epoch 92/100\n",
      "769500/769500 [==============================] - 22s 29us/step - loss: 3.0232 - mae: 3.0232 - val_loss: 10.8929 - val_mae: 10.8929\n",
      "Epoch 93/100\n",
      "769500/769500 [==============================] - 22s 29us/step - loss: 3.0271 - mae: 3.0271 - val_loss: 11.7303 - val_mae: 11.7303\n",
      "Epoch 94/100\n",
      "769500/769500 [==============================] - 22s 29us/step - loss: 3.0058 - mae: 3.0058 - val_loss: 11.3785 - val_mae: 11.3785\n",
      "Epoch 95/100\n",
      "769500/769500 [==============================] - 22s 29us/step - loss: 3.0140 - mae: 3.0140 - val_loss: 12.1017 - val_mae: 12.1017\n",
      "Epoch 96/100\n",
      "769500/769500 [==============================] - 22s 29us/step - loss: 2.9991 - mae: 2.9991 - val_loss: 11.4176 - val_mae: 11.4176\n",
      "Epoch 97/100\n",
      "769500/769500 [==============================] - 22s 29us/step - loss: 3.0012 - mae: 3.0012 - val_loss: 11.3825 - val_mae: 11.3825\n",
      "Epoch 98/100\n",
      "769500/769500 [==============================] - 22s 29us/step - loss: 2.9814 - mae: 2.9814 - val_loss: 10.3883 - val_mae: 10.3883\n",
      "Epoch 99/100\n",
      "769500/769500 [==============================] - 22s 29us/step - loss: 2.9573 - mae: 2.9573 - val_loss: 10.1132 - val_mae: 10.1132\n",
      "Epoch 100/100\n",
      "769500/769500 [==============================] - 22s 29us/step - loss: 2.9820 - mae: 2.9820 - val_loss: 11.5790 - val_mae: 11.5790\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1859497e3c8>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import BatchNormalization\n",
    "from keras import optimizers\n",
    "from keras import activations\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=168, activation='relu', input_dim=226))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(units=168, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(units=168, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(units=168, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(units=168, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(units=168, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(units=168, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(units=168, activation='relu'))\n",
    "model.add(Dense(units=4, activation='linear'))\n",
    "\n",
    "op  = optimizers.nadam(learning_rate=0.008)\n",
    "#모델을 컴파일합니다.\n",
    "model.compile(loss='mae', optimizer=op, metrics=['mae'])\n",
    "#모델을 학습합니다.\n",
    "model.fit(train_X, train_Y, epochs=100, batch_size=500, validation_split = 0.05)\n",
    "\n",
    "\n",
    "#예측값을 생성합니다.\n",
    "#pred_test = model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv(\"sample_submission.csv\")\n",
    "sample.iloc[:,1:] = pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>layer_1</th>\n",
       "      <th>layer_2</th>\n",
       "      <th>layer_3</th>\n",
       "      <th>layer_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>252.686630</td>\n",
       "      <td>229.252365</td>\n",
       "      <td>130.911804</td>\n",
       "      <td>88.178810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>156.946915</td>\n",
       "      <td>123.936295</td>\n",
       "      <td>240.474716</td>\n",
       "      <td>98.070915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>141.983627</td>\n",
       "      <td>179.935410</td>\n",
       "      <td>277.674744</td>\n",
       "      <td>153.981857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>92.604370</td>\n",
       "      <td>224.856064</td>\n",
       "      <td>190.588257</td>\n",
       "      <td>81.766197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>275.709137</td>\n",
       "      <td>293.152740</td>\n",
       "      <td>246.575180</td>\n",
       "      <td>270.859131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     layer_1     layer_2     layer_3     layer_4\n",
       "0   0  252.686630  229.252365  130.911804   88.178810\n",
       "1   1  156.946915  123.936295  240.474716   98.070915\n",
       "2   2  141.983627  179.935410  277.674744  153.981857\n",
       "3   3   92.604370  224.856064  190.588257   81.766197\n",
       "4   4  275.709137  293.152740  246.575180  270.859131"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.to_csv(\"sample_sub.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       250.0\n",
       "1       150.0\n",
       "2       140.0\n",
       "3        90.0\n",
       "4       270.0\n",
       "        ...  \n",
       "9995    120.0\n",
       "9996     80.0\n",
       "9997     40.0\n",
       "9998     30.0\n",
       "9999    160.0\n",
       "Name: layer_1, Length: 10000, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(sample[\"layer_1\"],-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py37] *",
   "language": "python",
   "name": "conda-env-py37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
