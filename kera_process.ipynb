{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "import numpy as np\n",
    "warnings.filterwarnings('ignore')\n",
    "train = pd.read_csv('trains.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "for col in train.columns:\n",
    "    col_type = train[col].dtypes\n",
    "    min1 = train[col].min()\n",
    "    max1 = train[col].max()\n",
    "    if str(col_type)[:3] == 'int':\n",
    "        train[col] = train[col].astype(np.int16)\n",
    "    else:\n",
    "        if min1 > np.finfo(np.float16).min and max1 < np.finfo(np.float16).max:\n",
    "            train[col] = train[col].astype(np.float16)\n",
    "        elif min1 > np.finfo(np.float32).min and max1 < np.finfo(np.float32).max:\n",
    "            train[col] = train[col].astype(np.float32)\n",
    "        else:\n",
    "            train[col] = train[col].astype(np.float64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train.iloc[:,4:]\n",
    "train_Y = train.iloc[:,0:4]\n",
    "test_X = test.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Activation\n",
    "from keras import optimizers\n",
    "from keras import activations\n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=168, activation='relu', input_dim=226))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(units=168, activation='relu'))\n",
    "    model.add(Dense(units=168, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(units=168, activation='relu'))\n",
    "    model.add(Dense(units=168, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(units=168, activation='relu'))\n",
    "    model.add(Dense(units=168, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(units=168, activation='relu'))\n",
    "    model.add(Dense(units=168, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(units=168, activation='relu'))\n",
    "    model.add(Dense(units=4, activation='linear'))\n",
    "    op  = optimizers.nadam(learning_rate=0.005)\n",
    "    model.compile(loss='mae', optimizer=op, metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 769500 samples, validate on 40500 samples\n",
      "Epoch 1/130\n",
      "769500/769500 [==============================] - 19s 24us/step - loss: 42.5472 - mae: 42.5471 - val_loss: 35.1952 - val_mae: 35.1952\n",
      "Epoch 2/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 17.5039 - mae: 17.5039 - val_loss: 26.5878 - val_mae: 26.5878\n",
      "Epoch 3/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 12.1069 - mae: 12.1069 - val_loss: 23.7458 - val_mae: 23.7458\n",
      "Epoch 4/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 9.8951 - mae: 9.8951 - val_loss: 20.7762 - val_mae: 20.7762\n",
      "Epoch 5/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 8.7394 - mae: 8.7394 - val_loss: 19.9971 - val_mae: 19.9971\n",
      "Epoch 6/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 7.9237 - mae: 7.9237 - val_loss: 19.3554 - val_mae: 19.3554\n",
      "Epoch 7/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 7.3710 - mae: 7.3710 - val_loss: 19.3638 - val_mae: 19.3638\n",
      "Epoch 8/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 6.9811 - mae: 6.9811 - val_loss: 21.1192 - val_mae: 21.1192\n",
      "Epoch 9/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 6.5905 - mae: 6.5905 - val_loss: 15.6302 - val_mae: 15.6302\n",
      "Epoch 10/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 6.2442 - mae: 6.2442 - val_loss: 17.5982 - val_mae: 17.5982\n",
      "Epoch 11/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 6.0473 - mae: 6.0473 - val_loss: 18.2704 - val_mae: 18.2704\n",
      "Epoch 12/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 5.8435 - mae: 5.8435 - val_loss: 18.0339 - val_mae: 18.0339\n",
      "Epoch 13/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 5.5952 - mae: 5.5952 - val_loss: 18.2949 - val_mae: 18.2949\n",
      "Epoch 14/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 5.4226 - mae: 5.4226 - val_loss: 15.8436 - val_mae: 15.8436\n",
      "Epoch 15/130\n",
      "769500/769500 [==============================] - 18s 24us/step - loss: 5.3437 - mae: 5.3437 - val_loss: 17.0756 - val_mae: 17.0756\n",
      "Epoch 16/130\n",
      "769500/769500 [==============================] - 18s 24us/step - loss: 5.1676 - mae: 5.1676 - val_loss: 14.9652 - val_mae: 14.9652\n",
      "Epoch 17/130\n",
      "769500/769500 [==============================] - 18s 24us/step - loss: 5.0474 - mae: 5.0474 - val_loss: 15.3137 - val_mae: 15.3137\n",
      "Epoch 18/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 4.9824 - mae: 4.9824 - val_loss: 15.9592 - val_mae: 15.9592\n",
      "Epoch 19/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 4.8172 - mae: 4.8172 - val_loss: 17.2865 - val_mae: 17.2865\n",
      "Epoch 20/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 4.8017 - mae: 4.8017 - val_loss: 13.9652 - val_mae: 13.9652\n",
      "Epoch 21/130\n",
      "769500/769500 [==============================] - 18s 24us/step - loss: 4.6424 - mae: 4.6424 - val_loss: 14.2511 - val_mae: 14.2511\n",
      "Epoch 22/130\n",
      "769500/769500 [==============================] - 18s 24us/step - loss: 4.6241 - mae: 4.6241 - val_loss: 13.8487 - val_mae: 13.8487\n",
      "Epoch 23/130\n",
      "769500/769500 [==============================] - 18s 24us/step - loss: 4.5658 - mae: 4.5658 - val_loss: 14.8993 - val_mae: 14.8993\n",
      "Epoch 24/130\n",
      "769500/769500 [==============================] - 18s 24us/step - loss: 4.4732 - mae: 4.4732 - val_loss: 16.9800 - val_mae: 16.9800\n",
      "Epoch 25/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 4.3932 - mae: 4.3932 - val_loss: 15.7160 - val_mae: 15.7160\n",
      "Epoch 26/130\n",
      "769500/769500 [==============================] - 18s 24us/step - loss: 4.2924 - mae: 4.2924 - val_loss: 15.3954 - val_mae: 15.3954\n",
      "Epoch 27/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 4.3163 - mae: 4.3163 - val_loss: 17.4884 - val_mae: 17.4884\n",
      "Epoch 28/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 4.2539 - mae: 4.2539 - val_loss: 12.2899 - val_mae: 12.2899\n",
      "Epoch 29/130\n",
      "769500/769500 [==============================] - 18s 24us/step - loss: 4.1698 - mae: 4.1698 - val_loss: 15.9377 - val_mae: 15.9377\n",
      "Epoch 30/130\n",
      "769500/769500 [==============================] - 18s 24us/step - loss: 4.1590 - mae: 4.1590 - val_loss: 14.3617 - val_mae: 14.3617\n",
      "Epoch 31/130\n",
      "769500/769500 [==============================] - 18s 24us/step - loss: 4.1101 - mae: 4.1101 - val_loss: 14.6308 - val_mae: 14.6308\n",
      "Epoch 32/130\n",
      "769500/769500 [==============================] - 18s 24us/step - loss: 4.0613 - mae: 4.0613 - val_loss: 15.0209 - val_mae: 15.0209\n",
      "Epoch 33/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 4.0461 - mae: 4.0461 - val_loss: 14.3516 - val_mae: 14.3516\n",
      "Epoch 34/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 3.9700 - mae: 3.9700 - val_loss: 12.5258 - val_mae: 12.5258\n",
      "Epoch 35/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 3.9446 - mae: 3.9446 - val_loss: 14.1105 - val_mae: 14.1105\n",
      "Epoch 36/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 3.9375 - mae: 3.9375 - val_loss: 13.2043 - val_mae: 13.2043\n",
      "Epoch 37/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 3.8910 - mae: 3.8910 - val_loss: 13.6346 - val_mae: 13.6346\n",
      "Epoch 38/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 3.8642 - mae: 3.8642 - val_loss: 13.7323 - val_mae: 13.7323\n",
      "Epoch 39/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 3.8078 - mae: 3.8078 - val_loss: 14.8350 - val_mae: 14.8350\n",
      "Epoch 40/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 3.8251 - mae: 3.8251 - val_loss: 12.3603 - val_mae: 12.3603\n",
      "Epoch 41/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 3.7503 - mae: 3.7503 - val_loss: 12.3868 - val_mae: 12.3868\n",
      "Epoch 42/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 3.7702 - mae: 3.7702 - val_loss: 13.7516 - val_mae: 13.7516\n",
      "Epoch 43/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 3.7319 - mae: 3.7319 - val_loss: 12.8915 - val_mae: 12.8915\n",
      "Epoch 44/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 3.6940 - mae: 3.6940 - val_loss: 15.2153 - val_mae: 15.2153\n",
      "Epoch 45/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 3.6573 - mae: 3.6573 - val_loss: 13.2979 - val_mae: 13.2979\n",
      "Epoch 46/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 3.6476 - mae: 3.6476 - val_loss: 13.0070 - val_mae: 13.0070\n",
      "Epoch 47/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 3.6528 - mae: 3.6528 - val_loss: 14.0199 - val_mae: 14.0199\n",
      "Epoch 48/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 3.6110 - mae: 3.6110 - val_loss: 13.2959 - val_mae: 13.2959\n",
      "Epoch 49/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 3.5953 - mae: 3.5953 - val_loss: 12.4036 - val_mae: 12.4036\n",
      "Epoch 50/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 3.5736 - mae: 3.5736 - val_loss: 13.0873 - val_mae: 13.0873\n",
      "Epoch 51/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 3.4832 - mae: 3.4832 - val_loss: 12.0613 - val_mae: 12.0613\n",
      "Epoch 52/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 3.5336 - mae: 3.5336 - val_loss: 13.6019 - val_mae: 13.6019\n",
      "Epoch 53/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 3.4961 - mae: 3.4961 - val_loss: 14.4940 - val_mae: 14.4940\n",
      "Epoch 54/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 3.4934 - mae: 3.4934 - val_loss: 12.1761 - val_mae: 12.1761\n",
      "Epoch 55/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 3.4823 - mae: 3.4823 - val_loss: 12.6639 - val_mae: 12.6639\n",
      "Epoch 56/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 3.4692 - mae: 3.4692 - val_loss: 13.3256 - val_mae: 13.3256\n",
      "Epoch 57/130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "769500/769500 [==============================] - 18s 23us/step - loss: 3.4236 - mae: 3.4236 - val_loss: 15.2937 - val_mae: 15.2937\n",
      "Epoch 58/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 3.4499 - mae: 3.4499 - val_loss: 13.0272 - val_mae: 13.0272\n",
      "Epoch 59/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 3.3943 - mae: 3.3943 - val_loss: 13.0799 - val_mae: 13.0799\n",
      "Epoch 60/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 3.3876 - mae: 3.3876 - val_loss: 12.2329 - val_mae: 12.2329\n",
      "Epoch 61/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 3.3762 - mae: 3.3762 - val_loss: 12.2470 - val_mae: 12.2470\n",
      "Epoch 62/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 3.3536 - mae: 3.3536 - val_loss: 12.6290 - val_mae: 12.6290\n",
      "Epoch 63/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 3.3417 - mae: 3.3417 - val_loss: 12.4844 - val_mae: 12.4844\n",
      "Epoch 64/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 3.3628 - mae: 3.3628 - val_loss: 12.7994 - val_mae: 12.7994\n",
      "Epoch 65/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 3.3251 - mae: 3.3251 - val_loss: 12.2162 - val_mae: 12.2162\n",
      "Epoch 66/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 3.2902 - mae: 3.2902 - val_loss: 12.1089 - val_mae: 12.1089\n",
      "Epoch 67/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 3.2670 - mae: 3.2670 - val_loss: 13.1695 - val_mae: 13.1695\n",
      "Epoch 68/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 3.3010 - mae: 3.3010 - val_loss: 12.1659 - val_mae: 12.1659\n",
      "Epoch 69/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 3.2706 - mae: 3.2706 - val_loss: 11.8668 - val_mae: 11.8668\n",
      "Epoch 70/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 3.2624 - mae: 3.2624 - val_loss: 13.1701 - val_mae: 13.1701\n",
      "Epoch 71/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 3.2374 - mae: 3.2374 - val_loss: 10.7659 - val_mae: 10.7659\n",
      "Epoch 72/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 3.2278 - mae: 3.2278 - val_loss: 12.2453 - val_mae: 12.2453\n",
      "Epoch 73/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 3.2173 - mae: 3.2173 - val_loss: 13.7083 - val_mae: 13.7083\n",
      "Epoch 74/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 3.2298 - mae: 3.2298 - val_loss: 11.7790 - val_mae: 11.7790\n",
      "Epoch 75/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 3.2498 - mae: 3.2498 - val_loss: 11.3860 - val_mae: 11.3860\n",
      "Epoch 76/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 3.1695 - mae: 3.1695 - val_loss: 11.4078 - val_mae: 11.4078\n",
      "Epoch 77/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 3.2032 - mae: 3.2032 - val_loss: 12.8582 - val_mae: 12.8582\n",
      "Epoch 78/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 3.1690 - mae: 3.1690 - val_loss: 11.2877 - val_mae: 11.2877\n",
      "Epoch 79/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 3.1619 - mae: 3.1619 - val_loss: 14.8154 - val_mae: 14.8154\n",
      "Epoch 80/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 3.1299 - mae: 3.1299 - val_loss: 12.7352 - val_mae: 12.7352\n",
      "Epoch 81/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 3.1669 - mae: 3.1669 - val_loss: 12.6002 - val_mae: 12.6002\n",
      "Epoch 82/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 3.1406 - mae: 3.1406 - val_loss: 13.4794 - val_mae: 13.4794\n",
      "Epoch 83/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 3.1471 - mae: 3.1471 - val_loss: 12.7795 - val_mae: 12.7795\n",
      "Epoch 84/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 3.1277 - mae: 3.1277 - val_loss: 11.6029 - val_mae: 11.6029\n",
      "Epoch 85/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 3.0912 - mae: 3.0912 - val_loss: 11.2572 - val_mae: 11.2572\n",
      "Epoch 86/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 3.1029 - mae: 3.1029 - val_loss: 12.1634 - val_mae: 12.1634\n",
      "Epoch 87/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 3.0949 - mae: 3.0949 - val_loss: 12.4002 - val_mae: 12.4002\n",
      "Epoch 88/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 3.0853 - mae: 3.0853 - val_loss: 11.9307 - val_mae: 11.9307\n",
      "Epoch 89/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 3.0808 - mae: 3.0808 - val_loss: 12.6186 - val_mae: 12.6186\n",
      "Epoch 90/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 3.0602 - mae: 3.0602 - val_loss: 12.0809 - val_mae: 12.0809\n",
      "Epoch 91/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 3.0682 - mae: 3.0682 - val_loss: 11.6639 - val_mae: 11.6639\n",
      "Epoch 92/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 3.0668 - mae: 3.0668 - val_loss: 11.8675 - val_mae: 11.8675\n",
      "Epoch 93/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 3.0474 - mae: 3.0474 - val_loss: 12.0794 - val_mae: 12.0794\n",
      "Epoch 94/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 3.0422 - mae: 3.0422 - val_loss: 12.0009 - val_mae: 12.0009\n",
      "Epoch 95/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 3.0049 - mae: 3.0049 - val_loss: 12.3200 - val_mae: 12.3200\n",
      "Epoch 96/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 3.0097 - mae: 3.0097 - val_loss: 12.0788 - val_mae: 12.0788\n",
      "Epoch 97/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 3.0058 - mae: 3.0058 - val_loss: 12.3163 - val_mae: 12.3163\n",
      "Epoch 98/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 3.0239 - mae: 3.0239 - val_loss: 12.7703 - val_mae: 12.7703\n",
      "Epoch 99/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 3.0052 - mae: 3.0052 - val_loss: 10.4811 - val_mae: 10.4811\n",
      "Epoch 100/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 3.0125 - mae: 3.0125 - val_loss: 11.8642 - val_mae: 11.8642\n",
      "Epoch 101/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 2.9872 - mae: 2.9872 - val_loss: 13.0208 - val_mae: 13.0208\n",
      "Epoch 102/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 2.9935 - mae: 2.9935 - val_loss: 12.7171 - val_mae: 12.7171\n",
      "Epoch 103/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 2.9784 - mae: 2.9784 - val_loss: 12.1990 - val_mae: 12.1990\n",
      "Epoch 104/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 2.9502 - mae: 2.9502 - val_loss: 12.6426 - val_mae: 12.6426\n",
      "Epoch 105/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 2.9616 - mae: 2.9616 - val_loss: 11.3411 - val_mae: 11.3411\n",
      "Epoch 106/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 2.9721 - mae: 2.9721 - val_loss: 13.4220 - val_mae: 13.4220\n",
      "Epoch 107/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 2.9326 - mae: 2.9326 - val_loss: 10.9418 - val_mae: 10.9418\n",
      "Epoch 108/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 2.9548 - mae: 2.9548 - val_loss: 11.7549 - val_mae: 11.7549\n",
      "Epoch 109/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 2.9191 - mae: 2.9191 - val_loss: 11.7417 - val_mae: 11.7417\n",
      "Epoch 110/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 2.8996 - mae: 2.8996 - val_loss: 12.0503 - val_mae: 12.0503\n",
      "Epoch 111/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 2.9312 - mae: 2.9312 - val_loss: 12.1449 - val_mae: 12.1449\n",
      "Epoch 112/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 2.9224 - mae: 2.9224 - val_loss: 12.4394 - val_mae: 12.4394\n",
      "Epoch 113/130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "769500/769500 [==============================] - 18s 23us/step - loss: 2.8960 - mae: 2.8960 - val_loss: 12.4535 - val_mae: 12.4535\n",
      "Epoch 114/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 2.9308 - mae: 2.9308 - val_loss: 13.4798 - val_mae: 13.4798\n",
      "Epoch 115/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 2.9038 - mae: 2.9038 - val_loss: 12.3088 - val_mae: 12.3088\n",
      "Epoch 116/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 2.9027 - mae: 2.9027 - val_loss: 12.9302 - val_mae: 12.9302\n",
      "Epoch 117/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 2.8675 - mae: 2.8675 - val_loss: 12.5797 - val_mae: 12.5797\n",
      "Epoch 118/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 2.8954 - mae: 2.8954 - val_loss: 11.1668 - val_mae: 11.1668\n",
      "Epoch 119/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 2.8709 - mae: 2.8709 - val_loss: 10.8691 - val_mae: 10.8691\n",
      "Epoch 120/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 2.8696 - mae: 2.8696 - val_loss: 11.0125 - val_mae: 11.0125\n",
      "Epoch 121/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 2.8630 - mae: 2.8630 - val_loss: 11.1760 - val_mae: 11.1760\n",
      "Epoch 122/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 2.8876 - mae: 2.8876 - val_loss: 11.0759 - val_mae: 11.0759\n",
      "Epoch 123/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 2.8534 - mae: 2.8534 - val_loss: 11.9450 - val_mae: 11.9450\n",
      "Epoch 124/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 2.8648 - mae: 2.8648 - val_loss: 11.7211 - val_mae: 11.7211\n",
      "Epoch 125/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 2.8477 - mae: 2.8477 - val_loss: 13.1099 - val_mae: 13.1099\n",
      "Epoch 126/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 2.8685 - mae: 2.8685 - val_loss: 11.9420 - val_mae: 11.9420\n",
      "Epoch 127/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 2.8521 - mae: 2.8521 - val_loss: 12.2357 - val_mae: 12.2357\n",
      "Epoch 128/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 2.9373 - mae: 2.9373 - val_loss: 12.1375 - val_mae: 12.1375\n",
      "Epoch 129/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 2.7857 - mae: 2.7857 - val_loss: 11.6433 - val_mae: 11.6433\n",
      "Epoch 130/130\n",
      "769500/769500 [==============================] - 18s 23us/step - loss: 2.8273 - mae: 2.8273 - val_loss: 11.3768 - val_mae: 11.3768\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x24fb1f5c8d0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model1 = build_model()\n",
    "model1.fit(train_X, train_Y, epochs=130, batch_size=500, validation_split = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 769500 samples, validate on 40500 samples\n",
      "Epoch 1/130\n",
      "769500/769500 [==============================] - 21s 27us/step - loss: 54.2784 - mae: 54.2784 - val_loss: 50.6077 - val_mae: 50.6077\n",
      "Epoch 2/130\n",
      "769500/769500 [==============================] - 20s 26us/step - loss: 28.4744 - mae: 28.4744 - val_loss: 36.2805 - val_mae: 36.2805\n",
      "Epoch 3/130\n",
      "769500/769500 [==============================] - 20s 26us/step - loss: 16.4612 - mae: 16.4612 - val_loss: 27.2823 - val_mae: 27.2823\n",
      "Epoch 4/130\n",
      "769500/769500 [==============================] - 20s 27us/step - loss: 12.3825 - mae: 12.3826 - val_loss: 25.5599 - val_mae: 25.5599\n",
      "Epoch 5/130\n",
      "769500/769500 [==============================] - 20s 27us/step - loss: 10.3964 - mae: 10.3964 - val_loss: 22.6053 - val_mae: 22.6053\n",
      "Epoch 6/130\n",
      "769500/769500 [==============================] - 20s 26us/step - loss: 9.1791 - mae: 9.1791 - val_loss: 20.0007 - val_mae: 20.0007\n",
      "Epoch 7/130\n",
      "769500/769500 [==============================] - 20s 26us/step - loss: 8.3381 - mae: 8.3381 - val_loss: 19.0392 - val_mae: 19.0392\n",
      "Epoch 8/130\n",
      "769500/769500 [==============================] - 20s 26us/step - loss: 7.6777 - mae: 7.6777 - val_loss: 17.6036 - val_mae: 17.6036\n",
      "Epoch 9/130\n",
      "769500/769500 [==============================] - 20s 26us/step - loss: 7.1330 - mae: 7.1329 - val_loss: 16.5290 - val_mae: 16.5290\n",
      "Epoch 10/130\n",
      "769500/769500 [==============================] - 20s 26us/step - loss: 6.7147 - mae: 6.7147 - val_loss: 17.5215 - val_mae: 17.5215\n",
      "Epoch 11/130\n",
      "769500/769500 [==============================] - 20s 26us/step - loss: 6.4213 - mae: 6.4213 - val_loss: 18.9758 - val_mae: 18.9758\n",
      "Epoch 12/130\n",
      "769500/769500 [==============================] - 20s 26us/step - loss: 6.0625 - mae: 6.0625 - val_loss: 17.5983 - val_mae: 17.5983\n",
      "Epoch 13/130\n",
      "769500/769500 [==============================] - 20s 26us/step - loss: 5.8489 - mae: 5.8488 - val_loss: 14.3008 - val_mae: 14.3008\n",
      "Epoch 14/130\n",
      "769500/769500 [==============================] - 20s 26us/step - loss: 5.6402 - mae: 5.6402 - val_loss: 16.4970 - val_mae: 16.4970\n",
      "Epoch 15/130\n",
      "769500/769500 [==============================] - 21s 27us/step - loss: 5.4533 - mae: 5.4534 - val_loss: 15.9089 - val_mae: 15.9089\n",
      "Epoch 16/130\n",
      "769500/769500 [==============================] - 20s 26us/step - loss: 5.2846 - mae: 5.2846 - val_loss: 14.2877 - val_mae: 14.2877\n",
      "Epoch 17/130\n",
      "769500/769500 [==============================] - 20s 26us/step - loss: 5.1182 - mae: 5.1182 - val_loss: 14.3911 - val_mae: 14.3911\n",
      "Epoch 18/130\n",
      "769500/769500 [==============================] - 20s 26us/step - loss: 4.9862 - mae: 4.9862 - val_loss: 13.3551 - val_mae: 13.3551\n",
      "Epoch 19/130\n",
      "769500/769500 [==============================] - 20s 26us/step - loss: 4.8732 - mae: 4.8732 - val_loss: 16.3729 - val_mae: 16.3729\n",
      "Epoch 20/130\n",
      "769500/769500 [==============================] - 21s 27us/step - loss: 4.7139 - mae: 4.7139 - val_loss: 13.7016 - val_mae: 13.7016\n",
      "Epoch 21/130\n",
      "769500/769500 [==============================] - 20s 27us/step - loss: 4.6364 - mae: 4.6364 - val_loss: 14.9344 - val_mae: 14.9344\n",
      "Epoch 22/130\n",
      "769500/769500 [==============================] - 20s 26us/step - loss: 4.5309 - mae: 4.5309 - val_loss: 15.4436 - val_mae: 15.4436\n",
      "Epoch 23/130\n",
      "769500/769500 [==============================] - 21s 27us/step - loss: 4.4547 - mae: 4.4547 - val_loss: 13.6762 - val_mae: 13.6762\n",
      "Epoch 24/130\n",
      "769500/769500 [==============================] - 20s 26us/step - loss: 4.3740 - mae: 4.3740 - val_loss: 14.6398 - val_mae: 14.6398\n",
      "Epoch 25/130\n",
      "769500/769500 [==============================] - 22s 28us/step - loss: 4.2785 - mae: 4.2785 - val_loss: 12.9103 - val_mae: 12.9102\n",
      "Epoch 26/130\n",
      "769500/769500 [==============================] - 21s 27us/step - loss: 4.2231 - mae: 4.2231 - val_loss: 13.4495 - val_mae: 13.4495\n",
      "Epoch 27/130\n",
      "769500/769500 [==============================] - 20s 26us/step - loss: 4.1047 - mae: 4.1047 - val_loss: 12.6561 - val_mae: 12.6561\n",
      "Epoch 28/130\n",
      "769500/769500 [==============================] - 20s 27us/step - loss: 4.0637 - mae: 4.0637 - val_loss: 11.4777 - val_mae: 11.4777\n",
      "Epoch 29/130\n",
      "769500/769500 [==============================] - 20s 27us/step - loss: 3.9937 - mae: 3.9937 - val_loss: 12.7240 - val_mae: 12.7240\n",
      "Epoch 30/130\n",
      "769500/769500 [==============================] - 21s 27us/step - loss: 3.9480 - mae: 3.9480 - val_loss: 13.6289 - val_mae: 13.6289\n",
      "Epoch 31/130\n",
      "769500/769500 [==============================] - 23s 29us/step - loss: 3.8698 - mae: 3.8698 - val_loss: 11.3943 - val_mae: 11.3943\n",
      "Epoch 32/130\n",
      "769500/769500 [==============================] - 22s 29us/step - loss: 3.8459 - mae: 3.8459 - val_loss: 14.6893 - val_mae: 14.6893\n",
      "Epoch 33/130\n",
      "769500/769500 [==============================] - 22s 28us/step - loss: 3.7842 - mae: 3.7842 - val_loss: 12.8069 - val_mae: 12.8069\n",
      "Epoch 34/130\n",
      "769500/769500 [==============================] - 21s 27us/step - loss: 3.7448 - mae: 3.7448 - val_loss: 12.8182 - val_mae: 12.8182\n",
      "Epoch 35/130\n",
      "769500/769500 [==============================] - 21s 27us/step - loss: 3.7078 - mae: 3.7078 - val_loss: 11.8730 - val_mae: 11.8730\n",
      "Epoch 36/130\n",
      "769500/769500 [==============================] - 20s 27us/step - loss: 3.6424 - mae: 3.6424 - val_loss: 12.0275 - val_mae: 12.0275\n",
      "Epoch 37/130\n",
      "769500/769500 [==============================] - 20s 26us/step - loss: 3.6289 - mae: 3.6289 - val_loss: 11.7454 - val_mae: 11.7454\n",
      "Epoch 38/130\n",
      "769500/769500 [==============================] - 21s 27us/step - loss: 3.5737 - mae: 3.5737 - val_loss: 11.4895 - val_mae: 11.4895\n",
      "Epoch 39/130\n",
      "769500/769500 [==============================] - 20s 26us/step - loss: 3.5458 - mae: 3.5458 - val_loss: 11.0203 - val_mae: 11.0203\n",
      "Epoch 40/130\n",
      "769500/769500 [==============================] - 20s 26us/step - loss: 3.5249 - mae: 3.5249 - val_loss: 11.2362 - val_mae: 11.2362\n",
      "Epoch 41/130\n",
      "769500/769500 [==============================] - 20s 27us/step - loss: 3.4675 - mae: 3.4675 - val_loss: 12.9190 - val_mae: 12.9190\n",
      "Epoch 42/130\n",
      "769500/769500 [==============================] - 21s 27us/step - loss: 3.4462 - mae: 3.4462 - val_loss: 11.5467 - val_mae: 11.5467\n",
      "Epoch 43/130\n",
      "769500/769500 [==============================] - 21s 27us/step - loss: 3.4304 - mae: 3.4304 - val_loss: 10.6555 - val_mae: 10.6555\n",
      "Epoch 44/130\n",
      "769500/769500 [==============================] - 21s 27us/step - loss: 3.3993 - mae: 3.3993 - val_loss: 11.6526 - val_mae: 11.6526\n",
      "Epoch 45/130\n",
      "769500/769500 [==============================] - 21s 27us/step - loss: 3.3611 - mae: 3.3611 - val_loss: 11.4252 - val_mae: 11.4252\n",
      "Epoch 46/130\n",
      "769500/769500 [==============================] - 21s 27us/step - loss: 3.3413 - mae: 3.3413 - val_loss: 13.8070 - val_mae: 13.8070\n",
      "Epoch 47/130\n",
      "769500/769500 [==============================] - 21s 27us/step - loss: 3.3149 - mae: 3.3149 - val_loss: 10.6859 - val_mae: 10.6859\n",
      "Epoch 48/130\n",
      "769500/769500 [==============================] - 20s 27us/step - loss: 3.2811 - mae: 3.2811 - val_loss: 12.2266 - val_mae: 12.2266\n",
      "Epoch 49/130\n",
      "769500/769500 [==============================] - 20s 26us/step - loss: 3.2564 - mae: 3.2564 - val_loss: 10.3849 - val_mae: 10.3849\n",
      "Epoch 50/130\n",
      "769500/769500 [==============================] - 21s 27us/step - loss: 3.2269 - mae: 3.2269 - val_loss: 11.3571 - val_mae: 11.3571\n",
      "Epoch 51/130\n",
      "769500/769500 [==============================] - 21s 27us/step - loss: 3.2293 - mae: 3.2293 - val_loss: 10.6529 - val_mae: 10.6529\n",
      "Epoch 52/130\n",
      "769500/769500 [==============================] - 21s 27us/step - loss: 3.1897 - mae: 3.1897 - val_loss: 11.1393 - val_mae: 11.1393\n",
      "Epoch 53/130\n",
      "769500/769500 [==============================] - 21s 27us/step - loss: 3.1546 - mae: 3.1546 - val_loss: 11.4645 - val_mae: 11.4645\n",
      "Epoch 54/130\n",
      "769500/769500 [==============================] - 21s 27us/step - loss: 3.1449 - mae: 3.1449 - val_loss: 12.1787 - val_mae: 12.1787\n",
      "Epoch 55/130\n",
      "769500/769500 [==============================] - 21s 27us/step - loss: 3.1309 - mae: 3.1309 - val_loss: 11.0324 - val_mae: 11.0324\n",
      "Epoch 56/130\n",
      "769500/769500 [==============================] - 21s 27us/step - loss: 3.1059 - mae: 3.1059 - val_loss: 10.8047 - val_mae: 10.8047\n",
      "Epoch 57/130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "769500/769500 [==============================] - 21s 27us/step - loss: 3.0833 - mae: 3.0833 - val_loss: 11.0610 - val_mae: 11.0610\n",
      "Epoch 58/130\n",
      "769500/769500 [==============================] - 20s 27us/step - loss: 3.0676 - mae: 3.0676 - val_loss: 11.3105 - val_mae: 11.3105\n",
      "Epoch 59/130\n",
      "769500/769500 [==============================] - 20s 27us/step - loss: 3.0434 - mae: 3.0434 - val_loss: 10.1769 - val_mae: 10.1769\n",
      "Epoch 60/130\n",
      "769500/769500 [==============================] - 21s 27us/step - loss: 3.0378 - mae: 3.0378 - val_loss: 11.0295 - val_mae: 11.0295\n",
      "Epoch 61/130\n",
      "769500/769500 [==============================] - 20s 26us/step - loss: 3.0001 - mae: 3.0001 - val_loss: 11.7055 - val_mae: 11.7055\n",
      "Epoch 62/130\n",
      "769500/769500 [==============================] - 20s 27us/step - loss: 2.9951 - mae: 2.9951 - val_loss: 9.3328 - val_mae: 9.3328\n",
      "Epoch 63/130\n",
      "769500/769500 [==============================] - 20s 27us/step - loss: 2.9720 - mae: 2.9720 - val_loss: 10.2526 - val_mae: 10.2526\n",
      "Epoch 64/130\n",
      "769500/769500 [==============================] - 21s 27us/step - loss: 2.9590 - mae: 2.9590 - val_loss: 11.5454 - val_mae: 11.5454\n",
      "Epoch 65/130\n",
      "769500/769500 [==============================] - 21s 27us/step - loss: 2.9501 - mae: 2.9501 - val_loss: 11.4408 - val_mae: 11.4408\n",
      "Epoch 66/130\n",
      "769500/769500 [==============================] - 20s 27us/step - loss: 2.9408 - mae: 2.9408 - val_loss: 10.6947 - val_mae: 10.6947\n",
      "Epoch 67/130\n",
      "769500/769500 [==============================] - 21s 27us/step - loss: 2.9028 - mae: 2.9028 - val_loss: 9.5897 - val_mae: 9.5897\n",
      "Epoch 68/130\n",
      "769500/769500 [==============================] - 21s 27us/step - loss: 2.8995 - mae: 2.8995 - val_loss: 10.0216 - val_mae: 10.0216\n",
      "Epoch 69/130\n",
      "769500/769500 [==============================] - 21s 27us/step - loss: 2.8716 - mae: 2.8716 - val_loss: 10.3195 - val_mae: 10.3195\n",
      "Epoch 70/130\n",
      "769500/769500 [==============================] - 21s 27us/step - loss: 2.8827 - mae: 2.8827 - val_loss: 10.7983 - val_mae: 10.7983\n",
      "Epoch 71/130\n",
      "769500/769500 [==============================] - 21s 27us/step - loss: 2.8585 - mae: 2.8585 - val_loss: 10.8207 - val_mae: 10.8207\n",
      "Epoch 72/130\n",
      "769500/769500 [==============================] - 21s 27us/step - loss: 2.8347 - mae: 2.8347 - val_loss: 11.8974 - val_mae: 11.8974\n",
      "Epoch 73/130\n",
      "769500/769500 [==============================] - 21s 27us/step - loss: 2.8153 - mae: 2.8153 - val_loss: 9.8934 - val_mae: 9.8934\n",
      "Epoch 74/130\n",
      "769500/769500 [==============================] - 21s 27us/step - loss: 2.8017 - mae: 2.8017 - val_loss: 10.2317 - val_mae: 10.2317\n",
      "Epoch 75/130\n",
      "769500/769500 [==============================] - 20s 27us/step - loss: 2.8084 - mae: 2.8084 - val_loss: 9.7550 - val_mae: 9.7550\n",
      "Epoch 76/130\n",
      "769500/769500 [==============================] - 21s 27us/step - loss: 2.7953 - mae: 2.7953 - val_loss: 10.9064 - val_mae: 10.9064\n",
      "Epoch 77/130\n",
      "769500/769500 [==============================] - 21s 27us/step - loss: 2.7898 - mae: 2.7898 - val_loss: 9.1890 - val_mae: 9.1890\n",
      "Epoch 78/130\n",
      "769500/769500 [==============================] - 20s 27us/step - loss: 2.7660 - mae: 2.7660 - val_loss: 8.6602 - val_mae: 8.6602\n",
      "Epoch 79/130\n",
      "769500/769500 [==============================] - 21s 27us/step - loss: 2.7676 - mae: 2.7676 - val_loss: 9.1501 - val_mae: 9.1501\n",
      "Epoch 80/130\n",
      "769500/769500 [==============================] - 21s 27us/step - loss: 2.7445 - mae: 2.7445 - val_loss: 8.9438 - val_mae: 8.9438\n",
      "Epoch 81/130\n",
      "769500/769500 [==============================] - 21s 27us/step - loss: 2.7307 - mae: 2.7307 - val_loss: 10.2976 - val_mae: 10.2976\n",
      "Epoch 82/130\n",
      "769500/769500 [==============================] - 21s 27us/step - loss: 2.7391 - mae: 2.7391 - val_loss: 9.1085 - val_mae: 9.1085\n",
      "Epoch 83/130\n",
      "769500/769500 [==============================] - 21s 27us/step - loss: 2.7126 - mae: 2.7126 - val_loss: 10.2705 - val_mae: 10.2705\n",
      "Epoch 84/130\n",
      "769500/769500 [==============================] - 21s 27us/step - loss: 2.6930 - mae: 2.6930 - val_loss: 12.0241 - val_mae: 12.0241\n",
      "Epoch 85/130\n",
      "769500/769500 [==============================] - 20s 27us/step - loss: 2.6976 - mae: 2.6976 - val_loss: 9.5331 - val_mae: 9.5331\n",
      "Epoch 86/130\n",
      "769500/769500 [==============================] - 20s 26us/step - loss: 2.6927 - mae: 2.6927 - val_loss: 10.2804 - val_mae: 10.2804\n",
      "Epoch 87/130\n",
      "769500/769500 [==============================] - 21s 27us/step - loss: 2.6751 - mae: 2.6751 - val_loss: 10.0223 - val_mae: 10.0223\n",
      "Epoch 88/130\n",
      "769500/769500 [==============================] - 21s 27us/step - loss: 2.6820 - mae: 2.6820 - val_loss: 10.2630 - val_mae: 10.2630\n",
      "Epoch 89/130\n",
      "769500/769500 [==============================] - 21s 27us/step - loss: 2.6502 - mae: 2.6502 - val_loss: 10.1655 - val_mae: 10.1655\n",
      "Epoch 90/130\n",
      "769500/769500 [==============================] - 21s 27us/step - loss: 2.6538 - mae: 2.6538 - val_loss: 9.8749 - val_mae: 9.8749\n",
      "Epoch 91/130\n",
      "769500/769500 [==============================] - 20s 27us/step - loss: 2.6385 - mae: 2.6385 - val_loss: 9.4189 - val_mae: 9.4189\n",
      "Epoch 92/130\n",
      "769500/769500 [==============================] - 21s 27us/step - loss: 2.6220 - mae: 2.6220 - val_loss: 9.7273 - val_mae: 9.7273\n",
      "Epoch 93/130\n",
      "769500/769500 [==============================] - 20s 26us/step - loss: 2.6216 - mae: 2.6216 - val_loss: 10.6756 - val_mae: 10.6756\n",
      "Epoch 94/130\n",
      "769500/769500 [==============================] - 20s 26us/step - loss: 2.6039 - mae: 2.6039 - val_loss: 9.3232 - val_mae: 9.3232\n",
      "Epoch 95/130\n",
      "769500/769500 [==============================] - 21s 27us/step - loss: 2.5976 - mae: 2.5976 - val_loss: 10.6457 - val_mae: 10.6457\n",
      "Epoch 96/130\n",
      "769500/769500 [==============================] - 21s 27us/step - loss: 2.5948 - mae: 2.5948 - val_loss: 10.5065 - val_mae: 10.5065\n",
      "Epoch 97/130\n",
      "769500/769500 [==============================] - 21s 27us/step - loss: 2.5981 - mae: 2.5981 - val_loss: 9.5235 - val_mae: 9.5235\n",
      "Epoch 98/130\n",
      "769500/769500 [==============================] - 21s 27us/step - loss: 2.5758 - mae: 2.5758 - val_loss: 10.0568 - val_mae: 10.0568\n",
      "Epoch 99/130\n",
      "769500/769500 [==============================] - 21s 27us/step - loss: 2.5723 - mae: 2.5723 - val_loss: 9.1505 - val_mae: 9.1505\n",
      "Epoch 100/130\n",
      "769500/769500 [==============================] - 21s 27us/step - loss: 2.5623 - mae: 2.5623 - val_loss: 10.1750 - val_mae: 10.1750\n",
      "Epoch 101/130\n",
      "769500/769500 [==============================] - 21s 27us/step - loss: 2.5528 - mae: 2.5528 - val_loss: 10.4363 - val_mae: 10.4363\n",
      "Epoch 102/130\n",
      "769500/769500 [==============================] - 21s 27us/step - loss: 2.5454 - mae: 2.5454 - val_loss: 10.0285 - val_mae: 10.0285\n",
      "Epoch 103/130\n",
      "769500/769500 [==============================] - 20s 26us/step - loss: 2.5354 - mae: 2.5354 - val_loss: 9.5917 - val_mae: 9.5917\n",
      "Epoch 104/130\n",
      "769500/769500 [==============================] - 20s 26us/step - loss: 2.5263 - mae: 2.5263 - val_loss: 9.7870 - val_mae: 9.7870\n",
      "Epoch 105/130\n",
      "769500/769500 [==============================] - 20s 27us/step - loss: 2.5163 - mae: 2.5163 - val_loss: 9.5877 - val_mae: 9.5877\n",
      "Epoch 106/130\n",
      "769500/769500 [==============================] - 21s 27us/step - loss: 2.5179 - mae: 2.5179 - val_loss: 10.4569 - val_mae: 10.4569\n",
      "Epoch 107/130\n",
      "769500/769500 [==============================] - 20s 27us/step - loss: 2.5142 - mae: 2.5142 - val_loss: 9.1337 - val_mae: 9.1337\n",
      "Epoch 108/130\n",
      "769500/769500 [==============================] - 20s 27us/step - loss: 2.5130 - mae: 2.5130 - val_loss: 9.7475 - val_mae: 9.7475\n",
      "Epoch 109/130\n",
      "769500/769500 [==============================] - 20s 27us/step - loss: 2.4909 - mae: 2.4909 - val_loss: 9.6479 - val_mae: 9.6479\n",
      "Epoch 110/130\n",
      "769500/769500 [==============================] - 21s 27us/step - loss: 2.4940 - mae: 2.4940 - val_loss: 10.5369 - val_mae: 10.5369\n",
      "Epoch 111/130\n",
      "769500/769500 [==============================] - 21s 27us/step - loss: 2.4774 - mae: 2.4774 - val_loss: 8.1950 - val_mae: 8.1950\n",
      "Epoch 112/130\n",
      "769500/769500 [==============================] - 21s 27us/step - loss: 2.4849 - mae: 2.4849 - val_loss: 9.8503 - val_mae: 9.8503\n",
      "Epoch 113/130\n",
      "769500/769500 [==============================] - 21s 27us/step - loss: 2.4585 - mae: 2.4585 - val_loss: 9.8806 - val_mae: 9.8806\n",
      "Epoch 114/130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "769500/769500 [==============================] - 21s 27us/step - loss: 2.4469 - mae: 2.4469 - val_loss: 9.9250 - val_mae: 9.9250\n",
      "Epoch 115/130\n",
      "769500/769500 [==============================] - 21s 27us/step - loss: 2.4764 - mae: 2.4764 - val_loss: 8.3931 - val_mae: 8.3931\n",
      "Epoch 116/130\n",
      "769500/769500 [==============================] - 21s 27us/step - loss: 2.4442 - mae: 2.4442 - val_loss: 9.2453 - val_mae: 9.2453\n",
      "Epoch 117/130\n",
      "769500/769500 [==============================] - 21s 27us/step - loss: 2.4307 - mae: 2.4307 - val_loss: 9.8116 - val_mae: 9.8116\n",
      "Epoch 118/130\n",
      "769500/769500 [==============================] - 20s 26us/step - loss: 2.4352 - mae: 2.4352 - val_loss: 10.2518 - val_mae: 10.2518\n",
      "Epoch 119/130\n",
      "769500/769500 [==============================] - 21s 27us/step - loss: 2.4222 - mae: 2.4222 - val_loss: 8.5371 - val_mae: 8.5371\n",
      "Epoch 120/130\n",
      "769500/769500 [==============================] - 21s 27us/step - loss: 2.4310 - mae: 2.4310 - val_loss: 8.5995 - val_mae: 8.5995\n",
      "Epoch 121/130\n",
      "769500/769500 [==============================] - 21s 27us/step - loss: 2.4115 - mae: 2.4115 - val_loss: 8.2332 - val_mae: 8.2332\n",
      "Epoch 122/130\n",
      "769500/769500 [==============================] - 21s 27us/step - loss: 2.4064 - mae: 2.4064 - val_loss: 9.8424 - val_mae: 9.8424\n",
      "Epoch 123/130\n",
      "769500/769500 [==============================] - 21s 27us/step - loss: 2.4121 - mae: 2.4121 - val_loss: 9.6268 - val_mae: 9.6268\n",
      "Epoch 124/130\n",
      "769500/769500 [==============================] - 20s 26us/step - loss: 2.3937 - mae: 2.3937 - val_loss: 9.7479 - val_mae: 9.7479\n",
      "Epoch 125/130\n",
      "769500/769500 [==============================] - 21s 27us/step - loss: 2.3968 - mae: 2.3968 - val_loss: 9.4495 - val_mae: 9.4495\n",
      "Epoch 126/130\n",
      "769500/769500 [==============================] - 21s 27us/step - loss: 2.3797 - mae: 2.3797 - val_loss: 9.1950 - val_mae: 9.1950\n",
      "Epoch 127/130\n",
      "769500/769500 [==============================] - 21s 27us/step - loss: 2.3766 - mae: 2.3766 - val_loss: 11.0139 - val_mae: 11.0139\n",
      "Epoch 128/130\n",
      "769500/769500 [==============================] - 20s 26us/step - loss: 2.3788 - mae: 2.3788 - val_loss: 8.4775 - val_mae: 8.4775\n",
      "Epoch 129/130\n",
      "769500/769500 [==============================] - 20s 26us/step - loss: 2.3596 - mae: 2.3595 - val_loss: 9.5044 - val_mae: 9.5044\n",
      "Epoch 130/130\n",
      "769500/769500 [==============================] - 20s 27us/step - loss: 2.3610 - mae: 2.3610 - val_loss: 9.1231 - val_mae: 9.1231\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x24f92f2b2e8>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = build_model()\n",
    "model1.fit(train_X, train_Y, epochs=130, batch_size=500, validation_split = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = model1.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv(\"sample_submission.csv\")\n",
    "sample.iloc[:,1:] = pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.to_csv(\"sample_sub.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py37] *",
   "language": "python",
   "name": "conda-env-py37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
